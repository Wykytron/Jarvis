=== SYSTEM PROMPT ===
You are ChatGPT, a helpful developer assistant. You have been provided with a subset of files from the Jarvis project. Use this context for answering any user questions about the code. Do not reveal sensitive information or partial content that was not provided.

=== FOLDER STRUCTURE (SELECTED) ===
v0.2/
    backend/
        agent/
            orchestrator.py
            blocks.py
            schemas.py
            prompts/
                plan_prompt.md

=== FILE CONTENTS ===

--- orchestrator.py ---
# agent/orchestrator.py

import json
import os
import logging
import openai

from openai import OpenAI

from .schemas import ALL_FUNCTION_SCHEMAS, PlanTasksArguments
from .blocks import (
    handle_parse_block,
    handle_sql_block,
    handle_output_block,
    handle_batch_insert_block
)
from agent.global_store import TABLE_SCHEMAS, CURRENT_DATETIME_FN

logger = logging.getLogger("agent")


def call_openai_plan(user_request: str, debug_info: list, task_memory: dict) -> PlanTasksArguments:
    """
    Calls GPT with plan instructions to produce a short JSON plan { tasks: [...] }.
    This is still the same approach, but we might add a usage example to plan_prompt.
    """
    base_dir = os.path.dirname(os.path.abspath(__file__))
    plan_path = os.path.join(base_dir, "prompts", "plan_prompt.md")
    with open(plan_path, "r", encoding="utf-8") as f:
        plan_instructions = f.read()

    model_name = task_memory.get("agent_model", "gpt-4-0613")

    messages = [
        {"role": "system", "content": plan_instructions},
        {"role": "user", "content": f"USER REQUEST: {user_request}"}
    ]

    logger.info(f"[call_openai_plan] user_request='{user_request}'")
    debug_info.append(f"[plan] user_request='{user_request}'")

    client = OpenAI(api_key=openai.api_key)
    resp = client.chat.completions.create(
        model=model_name,
        messages=messages,
        functions=[fn for fn in ALL_FUNCTION_SCHEMAS if fn["name"] == "plan_tasks"],
        function_call="auto",
        temperature=0.7
    )

    logger.info(f"[call_openai_plan] raw response => {resp}")
    debug_info.append(f"[plan] raw response => {resp}")

    choice = resp.choices[0]
    fn_call = choice.message.function_call
    if fn_call:
        fn_args_str = fn_call.arguments
        debug_info.append(f"[plan] function_call arguments => {fn_args_str}")
        try:
            data = json.loads(fn_args_str)
            plan_args = PlanTasksArguments(**data)
            logger.info(f"[call_openai_plan] Final plan => {plan_args.tasks}")
            debug_info.append(f"[plan] tasks => {plan_args.tasks}")
            return plan_args
        except Exception as e:
            debug_info.append(f"[plan] parse error => {e}")
            logger.warning(f"[call_openai_plan] parse error => {e}")
            return PlanTasksArguments(tasks=[])
    else:
        # fallback parse if no function_call
        content_str = choice.message.content or ""
        debug_info.append(f"[plan] no function_call, content => {content_str}")
        try:
            candidate = json.loads(content_str)
            if "name" in candidate and "arguments" in candidate:
                plan_args_data = candidate["arguments"]
                plan_args = PlanTasksArguments(**plan_args_data)
                logger.info(f"[call_openai_plan] Final plan => {plan_args.tasks}")
                debug_info.append(f"[plan] tasks => {plan_args.tasks}")
                return plan_args
        except:
            pass
        logger.info("[call_openai_plan] no tasks returned.")
        return PlanTasksArguments(tasks=[])


def build_system_prompt_for_block(block_name: str, block_description: str, task_memory: dict) -> str:
    """
    Provide specialized instructions for each block.
    Now we also handle 'batch_insert_block' with a short schema note.
    And we add a mention that parse_block can parse DB rows.
    """
    from agent.global_store import TABLE_SCHEMAS, CURRENT_DATETIME_FN

    if block_name == "parse_block":
        user_req = task_memory.get("original_user_input", "")
        date_str = ""
        if CURRENT_DATETIME_FN:
            dt_now = CURRENT_DATETIME_FN()
            date_str = f"Current date/time => {dt_now.isoformat()}\n"

        target_table = task_memory.get("target_table", "(none)")
        table_cols = TABLE_SCHEMAS.get(target_table, [])
        col_list_str = ", ".join(table_cols)

        # If we have last_sql_rows in memory, we can mention it to the LLM
        last_rows = task_memory.get("last_sql_rows", [])
        # We'll just embed them in the system prompt:
        last_rows_str = json.dumps(last_rows, default=str)

        return (
            "You are the 'parse_block'. You can parse or unify user text AND/OR data from the DB.\n"
            "Sometimes we do: 1) SELECT from DB => we get db_rows => then parse them to fill missing columns.\n"
            "If 'db_rows' is provided, unify or fill columns. If user says '1 liter', parse quantity=1.0, unit='liter'.\n"
            "If user says 'expires next week', convert to a date offset.\n"
            "Return function_call => { raw_text:'...', explanation:'...', db_rows:..., parsed_item:{...} }.\n\n"
            f"{date_str}"
            f"Target table => {target_table}\n"
            f"Columns => {col_list_str}\n"
            f"last_sql_rows => {last_rows_str}\n"
            f"user_input => {user_req}\n"
            f"task_memory => {json.dumps(task_memory, default=str)}"
        )

    elif block_name == "sql_block":
        db_schema_str = (
            "Here is your DB schema:\n"
            "- fridge_items:\n"
            "   columns => [id, name, quantity, unit, expiration_date, category] (ALWAYS_ALLOW)\n"
            "- shopping_items:\n"
            "   columns => [id, name, desired_quantity, unit, purchased] (ALWAYS_ALLOW)\n"
            "- invoices:\n"
            "   columns => [id, date, total_amount, store_name] (REQUIRE_USER)\n"
            "- invoice_items:\n"
            "   columns => [id, invoice_id, name, quantity, price_per_unit] (REQUIRE_USER)\n"
            "- monthly_spendings:\n"
            "   columns => [id, year_month, total_spent] (ALWAYS_DENY)\n"
        )
        return (
            "You are 'sql_block'. You produce JSON => { table_name, columns, values, action_type, explanation, [where_clause] }.\n"
            "No disclaimers. If user says 'delete X', do DELETE with a proper where_clause.\n"
            "If user says 'update X', do UPDATE with a proper where_clause.\n"
            "You MUST always provide a where_clause if action_type=DELETE or UPDATE.\n"
            "If user wants to fill missing columns after parse_block, incorporate them.\n\n"
            + db_schema_str
            + "\n"
            + "task_memory => "
            + json.dumps(task_memory, default=str)
        )

    elif block_name == "output_block":
        last_sql = task_memory.get("last_sql_block_result", {})
        return (
            "You are 'output_block'. Summarize or finalize the answer.\n"
            "Override if rowcount=0 => say 'No items found or changed', or if there's an error.\n"
            f"last_sql_block_result => {json.dumps(last_sql, default=str)}\n"
            f"task_memory => {json.dumps(task_memory, default=str)}"
        )

    elif block_name == "batch_insert_block":
        db_schema_str = (
            "Here is your DB schema:\n"
            "- fridge_items:\n"
            "   columns => [id, name, quantity, unit, expiration_date, category] (ALWAYS_ALLOW)\n"
            "- shopping_items:\n"
            "   columns => [id, name, desired_quantity, unit, purchased] (ALWAYS_ALLOW)\n"
            "- invoices:\n"
            "   columns => [id, date, total_amount, store_name] (REQUIRE_USER)\n"
            "- invoice_items:\n"
            "   columns => [id, invoice_id, name, quantity, price_per_unit] (REQUIRE_USER)\n"
            "- monthly_spendings:\n"
            "   columns => [id, year_month, total_spent] (ALWAYS_DENY)\n"
        )
        return (
            "You are 'batch_insert_block'. You receive { table_name, rows:[{columns, values},...], explanation}.\n"
            "No disclaimers. Insert multiple rows into the DB.\n\n"
            + db_schema_str
            + "\n"
            + "task_memory => "
            + json.dumps(task_memory, default=str)
        )

    else:
        return f"You are block={block_name}, partial memory => {json.dumps(task_memory, default=str)}"


def call_block_llm(block_name: str, block_description: str, task_memory: dict, debug_info: list):
    """
    Calls GPT with the appropriate function schema.
    Then dispatches to the matching handler: parse_block, sql_block, etc.
    """
    logger.info(f"[call_block_llm] block={block_name}, desc={block_description}")
    debug_info.append(f"[block_llm] block={block_name}, desc={block_description}")

    schema = None
    for s in ALL_FUNCTION_SCHEMAS:
        if s["name"] == block_name:
            schema = s
            break

    if not schema:
        msg = f"No schema found for block={block_name}"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}

    system_prompt = build_system_prompt_for_block(block_name, block_description, task_memory)
    model_name = task_memory.get("agent_model", "gpt-4-0613")

    client = OpenAI(api_key=openai.api_key)
    resp = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": block_description}
        ],
        functions=[schema],
        function_call="auto",
        temperature=0.7
    )
    logger.info(f"[call_block_llm] LLM resp => {resp}")
    debug_info.append(f"[block_llm] raw response => {resp}")

    choice = resp.choices[0]
    fn_call = choice.message.function_call
    if not fn_call:
        # fallback parse
        content_str = choice.message.content or ""
        debug_info.append(f"[block_llm] no function_call => fallback parse content = {content_str}")
        try:
            candidate = json.loads(content_str)
            if "name" in candidate and "arguments" in candidate:
                fallback_args = candidate["arguments"]
                logger.info(f"[call_block_llm] fallback parse => block={block_name}, arguments={fallback_args}")
                return dispatch_block(block_name, fallback_args, task_memory, debug_info)
        except Exception as e:
            msg = f"No function_call returned, fallback parse error => {e}"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        return {"error": "No function_call returned and fallback parse didn't match block."}
    else:
        fn_args_str = fn_call.arguments
        debug_info.append(f"[block_llm] function_call args => {fn_args_str}")
        logger.info(f"[call_block_llm] function_call args => {fn_args_str}")
        try:
            args_data = json.loads(fn_args_str)
        except Exception as e:
            debug_info.append(f"[block_llm] JSON parse error => {e}")
            return {"error": f"JSON parse error => {e}"}
        return dispatch_block(block_name, args_data, task_memory, debug_info)


def dispatch_block(block_name: str, args_data: dict, task_memory: dict, debug_info: list):
    logger.info(f"[dispatch_block] block={block_name}, args={args_data}")
    debug_info.append(f"[dispatch_block] block={block_name}, args={args_data}")

    if ("table_name" in args_data
        and block_name in ["sql_block","batch_insert_block"]):
        guessed_table = args_data["table_name"]
        debug_info.append(f"[dispatch_block] Setting target_table => {guessed_table}")
        task_memory["target_table"] = guessed_table

    from .blocks import (
        handle_parse_block,
        handle_sql_block,
        handle_output_block,
        handle_batch_insert_block
    )

    if block_name == "parse_block":
        return handle_parse_block(args_data, task_memory, debug_info)
    elif block_name == "sql_block":
        return handle_sql_block(args_data, task_memory, debug_info)
    elif block_name == "output_block":
        return handle_output_block(args_data, task_memory, debug_info)
    elif block_name == "batch_insert_block":
        return handle_batch_insert_block(args_data, task_memory, debug_info)
    else:
        msg = f"Unrecognized block => {block_name}"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}


def run_agent(user_input: str, initial_task_memory: dict = None):
    """
    Orchestrates the user request -> plan -> block calls -> final answer.
    If no output_block triggered, we produce a fallback answer (SELECT results, rowcount, etc).
    """
    debug_info = []
    if not initial_task_memory:
        initial_task_memory = {}
    task_memory = {"original_user_input": user_input, **initial_task_memory}

    plan_result = call_openai_plan(user_input, debug_info, task_memory)
    if not plan_result.tasks:
        return ("Could not plan tasks. Possibly clarify your request.", debug_info)

    final_answer = "(No final answer produced)"
    output_block_triggered = False

    for step in plan_result.tasks:
        block = step.block
        desc = step.description

        # optional heuristic to guess table from desc
        if "fridge_items" in desc.lower():
            task_memory["target_table"] = "fridge_items"
        elif "shopping_list" in desc.lower() or "shopping_items" in desc.lower():
            task_memory["target_table"] = "shopping_items"
        elif "invoice" in desc.lower():
            task_memory["target_table"] = "invoices"

        result = call_block_llm(block, desc, task_memory, debug_info)
        task_memory[f"last_{block}_result"] = result

        if block == "output_block":
            output_block_triggered = True
            if "final_answer" in result:
                final_answer = result["final_answer"]
            else:
                fm = result.get("final_message", "")
                if fm:
                    final_answer = fm
            break

    if not output_block_triggered:
        last_sql_res = task_memory.get("last_sql_block_result", {})
        if "error" in last_sql_res:
            final_answer = "Sorry, an error occurred with your request:\n" + last_sql_res["error"]
        else:
            ra = last_sql_res.get("rows_affected", None)
            rc = last_sql_res.get("rows_count", None)
            rows_inserted = last_sql_res.get("rows_inserted", None)

            if rows_inserted is not None:
                if rows_inserted == 0:
                    final_answer = "No rows were inserted (possible mismatch)."
                else:
                    final_answer = f"Successfully inserted {rows_inserted} rows."
            elif ra is not None:
                if ra == 0:
                    final_answer = "No matching items were found to update/delete."
                else:
                    final_answer = "Success. The DB was updated."
            elif rc is not None:
                if rc == 0:
                    final_answer = "No items found."
                else:
                    final_answer = f"Found {rc} item(s)."
            else:
                final_answer = "Operation completed, but no final output_block was produced."

    return (final_answer, debug_info)

--- blocks.py ---
# agent/blocks.py

import re
import json
import logging
from typing import Any, Dict
from database import SessionLocal, table_permissions
from sqlalchemy import text
import datetime

logger = logging.getLogger("agent")

NAME_SYNONYMS = {
    "tomato": "tomatoes",
    "tomatoe": "tomatoes",
    "tomatoes": "tomatoes",
    # ...
}

DATE_SYNONYMS = {
    "today": 0,
    "tomorrow": 1,
    "next week": 7,
    # ...
}

def dictionary_normalize_item_name(raw: str) -> str:
    lowered = raw.strip().lower()
    return NAME_SYNONYMS.get(lowered, lowered)

def guess_quantity_and_unit_from_text(text: str) -> (float, str):
    match = re.search(
        r"(\d+(?:\.\d+)?)\s*(liter|liters|unit|units|bag|bags|piece|pieces)\b",
        text,
        re.IGNORECASE
    )
    if match:
        qty_str = match.group(1)
        unit_str = match.group(2)
        try:
            qty_val = float(qty_str)
        except:
            qty_val = 1.0
        return (qty_val, unit_str.lower())
    else:
        return (None, None)

def guess_expiration_date_from_text(text: str, current_dt_fn):
    match = re.search(r"(expires|expiring|expiry)\s+(today|tomorrow|next week)\b", text, re.IGNORECASE)
    if match:
        phrase = match.group(2).lower()
        offset_days = DATE_SYNONYMS.get(phrase, 0)
        now_dt = current_dt_fn() if current_dt_fn else datetime.datetime.utcnow()
        real_dt = now_dt + datetime.timedelta(days=offset_days)
        return real_dt.strftime("%Y-%m-%d")
    else:
        return None


def handle_parse_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    """
    parse_block can parse raw_text from user, but also can unify 'db_rows' if provided.
    We store the result in parsed_item or we can store additional logic.
    """
    raw_text = args.get("raw_text", "")
    explanation = args.get("explanation", "")
    parsed_item = args.get("parsed_item", {}) or {}

    # Optionally, if we have db_rows in the parse_block arguments:
    db_rows = args.get("db_rows", [])  # new field if you let LLM produce it

    debug_info.append(f"[parse_block] raw_text={raw_text}, explanation={explanation}, #db_rows={len(db_rows)}")

    from agent.global_store import TABLE_SCHEMAS, CURRENT_DATETIME_FN

    # Possibly unify synonyms if 'name' in parsed_item
    if "name" in parsed_item:
        old_name = parsed_item["name"]
        new_name = dictionary_normalize_item_name(old_name)
        parsed_item["name"] = new_name
        debug_info.append(f"[parse_block] Normalized name from '{old_name}' => '{new_name}'")

    # If no 'quantity' or 'unit', guess from raw_text
    if "quantity" not in parsed_item or "unit" not in parsed_item:
        (qty_guess, unit_guess) = guess_quantity_and_unit_from_text(raw_text)
        if qty_guess is not None and "quantity" not in parsed_item:
            parsed_item["quantity"] = qty_guess
        if unit_guess is not None and "unit" not in parsed_item:
            parsed_item["unit"] = unit_guess

    # If no expiration_date, guess from raw_text
    if "expiration_date" not in parsed_item:
        dt_guess = guess_expiration_date_from_text(raw_text, CURRENT_DATETIME_FN)
        if dt_guess:
            parsed_item["expiration_date"] = dt_guess

    # If we want to unify partial DB data as well
    # e.g. fill missing columns in each row, or something advanced.
    # For now, we just store the db_rows in memory so the LLM knows it can use them.
    # Or we can do more advanced logic here.
    if db_rows:
        debug_info.append(f"[parse_block] We also have {len(db_rows)} row(s) from the DB to parse/unify.")
        # In a real scenario, you might unify each row with parsed_item
        # or do some advanced merging logic. For now, we just keep them in memory:
        task_memory["last_parsed_db_rows"] = db_rows

    # Also fill missing columns if target_table is known
    target_table = task_memory.get("target_table", "")
    col_list = TABLE_SCHEMAS.get(target_table, [])
    debug_info.append(f"[parse_block] target_table => {target_table}, col_list => {col_list}")

    for c in col_list:
        if c not in parsed_item:
            if c == "quantity":
                parsed_item[c] = 1.0
            elif c == "unit":
                parsed_item[c] = "unit"
            elif c == "expiration_date":
                parsed_item[c] = None
            elif c == "category":
                parsed_item[c] = "misc"

    debug_info.append(f"[parse_block] final parsed_item => {parsed_item}")
    task_memory["parsed_item"] = parsed_item

    return {
        "success": True,
        "parsed_item": parsed_item,
        "db_rows": db_rows,
        "explanation": explanation
    }


def build_case_insensitive_where(where_str: str) -> str:
    pattern = r"(?i)WHERE\s+name\s*=\s*([\"'])(.*?)\1"
    replacement = r"WHERE LOWER(name)=LOWER(\1\2\1)"
    out = re.sub(pattern, replacement, where_str)
    return out

def quote_if_needed(val: str) -> str:
    trimmed = val.strip()
    if (trimmed.startswith("'") and trimmed.endswith("'")) or trimmed.replace(".", "", 1).isdigit():
        return trimmed
    return f"'{trimmed}'"


def handle_sql_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    """
    The normal single SQL action: SELECT, INSERT, UPDATE, DELETE.
    Potentially merges parse_block data into columns/values if action_type in [INSERT,UPDATE].
    """
    table_name = args.get("table_name", "").strip()
    columns = args.get("columns", [])
    values = args.get("values", [])
    action_type = args.get("action_type", "").upper()
    explanation = args.get("explanation", "")
    where_clause = args.get("where_clause", "").strip()

    debug_info.append(
        f"[sql_block] user gave => table={table_name}, cols={columns}, vals={values}, "
        f"action={action_type}, where={where_clause}"
    )

    parsed_item = task_memory.get("parsed_item", {})
    if parsed_item and action_type in ["INSERT","UPDATE"]:
        for col, val in parsed_item.items():
            if col not in columns:
                columns.append(col)
                val_str = "NULL" if val is None else str(val)
                values.append(val_str)
        debug_info.append(f"[sql_block] after merging parse_item => columns={columns}, values={values}")

    permission_mode = table_permissions.get(table_name, "ALWAYS_DENY")
    user_permission = True

    if action_type == "SELECT":
        if permission_mode == "ALWAYS_DENY":
            msg = f"[sql_block] SELECT on '{table_name}' => ALWAYS_DENY"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        col_list_str = "*"
        if columns:
            col_list_str = ", ".join(columns)
        sql_query = f"SELECT {col_list_str} FROM {table_name};"
        return run_select_query(sql_query, explanation, debug_info, task_memory)

    elif action_type == "INSERT":
        if permission_mode == "ALWAYS_DENY":
            msg = f"[sql_block] INSERT => table '{table_name}' => ALWAYS_DENY"
            debug_info.append(msg)
            return {"error": msg}

        if len(columns) != len(values):
            msg = f"[sql_block] Mismatch => columns={columns}, values={values}"
            debug_info.append(msg)
            return {"error": msg}

        col_list_str = ", ".join(columns)
        val_list_str = ", ".join(quote_if_needed(v) for v in values)
        sql_query = f"INSERT INTO {table_name}({col_list_str}) VALUES({val_list_str});"
        debug_info.append(f"[sql_block] final INSERT => {sql_query}")
        return run_write_query(sql_query, explanation, debug_info)

    elif action_type in ["UPDATE","DELETE"]:
        if permission_mode == "ALWAYS_DENY":
            msg = f"[sql_block] Writes to '{table_name}' => ALWAYS_DENY"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        if permission_mode == "REQUIRE_USER" and not user_permission:
            msg = f"[sql_block] Write to '{table_name}' => not granted"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        if not where_clause.upper().startswith("WHERE"):
            msg = f"[sql_block] {action_type} requested but no where_clause => not allowed!"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        ci_where = build_case_insensitive_where(where_clause)
        debug_info.append(f"[sql_block] transformed where => {ci_where}")
        where_clause = ci_where

        if action_type == "UPDATE":
            if len(columns) != len(values):
                msg = f"[sql_block] mismatch col vs val => {columns} vs {values}"
                debug_info.append(msg)
                return {"error": msg}
            set_clauses = []
            for c, v in zip(columns, values):
                set_clauses.append(f"{c}={quote_if_needed(v)}")
            set_stmt = ", ".join(set_clauses)
            sql_query = f"UPDATE {table_name} SET {set_stmt} {where_clause};"
            debug_info.append(f"[sql_block] final UPDATE => {sql_query}")
            return run_write_query(sql_query, explanation, debug_info)

        elif action_type == "DELETE":
            sql_query = f"DELETE FROM {table_name} {where_clause};"
            debug_info.append(f"[sql_block] final DELETE => {sql_query}")
            return run_write_query(sql_query, explanation, debug_info)

    else:
        msg = f"[sql_block] unrecognized action_type={action_type}"
        debug_info.append(msg)
        return {"error": msg}


def run_select_query(sql_query: str, explanation: str, debug_info: list, task_memory: dict) -> dict:
    db = SessionLocal()
    rows_data = []
    error_msg = None
    try:
        debug_info.append(f"[sql_block] Running SELECT => {sql_query}")
        result = db.execute(text(sql_query))
        all_rows = result.fetchall()
        for row in all_rows:
            row_dict = dict(row._mapping)
            rows_data.append(row_dict)
        debug_info.append(f"[sql_block] SELECT => got {len(rows_data)} row(s)")
        logger.info(f"[sql_block] success => SELECT '{sql_query}', rows={len(rows_data)}")
    except Exception as e:
        error_msg = str(e)
        debug_info.append(f"[sql_block] select error => {error_msg}")
        logger.warning(f"[sql_block] SELECT error => {error_msg}")
    finally:
        db.close()

    if error_msg:
        return {"error": error_msg, "sql_query": sql_query}
    # Store the rows in memory so parse_block can read them
    task_memory["last_sql_rows"] = rows_data
    return {
        "success": True,
        "rows_data": rows_data,
        "explanation": explanation,
        "rows_count": len(rows_data)
    }

def run_write_query(sql_query: str, explanation: str, debug_info: list) -> dict:
    db = SessionLocal()
    error_msg = None
    rowcount = 0
    try:
        debug_info.append(f"[sql_block] Running WRITE => {sql_query}")
        result = db.execute(text(sql_query))
        rowcount = result.rowcount or 0
        db.commit()
        debug_info.append(f"[sql_block] WRITE => rowcount={rowcount}")
        logger.info(f"[sql_block] success => WRITE '{sql_query}', rowcount={rowcount}")
    except Exception as e:
        error_msg = str(e)
        debug_info.append(f"[sql_block] write error => {error_msg}")
        logger.warning(f"[sql_block] WRITE error => {error_msg}")
        db.rollback()
    finally:
        db.close()

    if error_msg:
        return {"error": error_msg, "sql_query": sql_query}
    return {
        "success": True,
        "rows_affected": rowcount,
        "explanation": explanation
    }

def handle_batch_insert_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    """
    Insert multiple rows into a table in one go.
    """
    table_name = args.get("table_name","").strip()
    rows_info = args.get("rows", [])
    explanation = args.get("explanation","")

    debug_info.append(f"[batch_insert] table={table_name}, #rows={len(rows_info)}")

    permission_mode = table_permissions.get(table_name, "ALWAYS_DENY")
    user_permission = True

    if permission_mode == "ALWAYS_DENY":
        msg = f"[batch_insert_block] INSERT => table '{table_name}' => ALWAYS_DENY"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}

    if permission_mode == "REQUIRE_USER" and not user_permission:
        msg = f"[batch_insert_block] Write to '{table_name}' => not granted"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}

    inserted_count = 0
    error_msg = None
    db = SessionLocal()
    try:
        for row_data in rows_info:
            columns = row_data.get("columns", [])
            values = row_data.get("values", [])

            if len(columns) != len(values):
                raise ValueError(f"Mismatch in columns vs. values => {columns} vs. {values}")

            col_list_str = ", ".join(columns)
            val_list_str = ", ".join(quote_if_needed(v) for v in values)
            sql_query = f"INSERT INTO {table_name} ({col_list_str}) VALUES ({val_list_str});"
            debug_info.append(f"[batch_insert] running => {sql_query}")

            result = db.execute(text(sql_query))
            rowcount = result.rowcount or 0
            inserted_count += rowcount

        db.commit()
    except Exception as e:
        error_msg = str(e)
        debug_info.append(f"[batch_insert] error => {error_msg}")
        logger.warning(f"[batch_insert_block] error => {error_msg}")
        db.rollback()
    finally:
        db.close()

    if error_msg:
        return {"error": error_msg, "rows_inserted": inserted_count, "explanation": explanation}

    return {
        "success": True,
        "rows_inserted": inserted_count,
        "explanation": explanation
    }


def handle_output_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    llm_message = args.get("final_message", "").strip()
    if not llm_message:
        llm_message = "(No final_message provided by LLM)"

    last_sql_result = task_memory.get("last_sql_block_result", {})
    sql_error = last_sql_result.get("error", "")
    row_affected = last_sql_result.get("rows_affected", None)
    row_count = last_sql_result.get("rows_count", None)
    rows_inserted = last_sql_result.get("rows_inserted", None)

    if sql_error:
        final_msg = f"Sorry, an error occurred with your request:\n{sql_error}"
        debug_info.append("[output_block] Overriding LLM message due to SQL error.")
        return {"final_answer": final_msg}

    if rows_inserted is not None:
        if rows_inserted == 0:
            final_msg = "No rows were inserted. Possibly data mismatch or user canceled."
            debug_info.append("[output_block] Overriding LLM => no rows inserted.")
            return {"final_answer": final_msg}
        else:
            debug_info.append(f"[output_block] Inserted {rows_inserted} => letting LLM message stand.")
            return {"final_answer": llm_message}

    if row_affected is not None:
        if row_affected == 0:
            final_msg = (
                "No matching items were found to update/delete. "
                "If you expected a change, please check the name."
            )
            debug_info.append("[output_block] Overriding LLM => no row changed.")
            return {"final_answer": final_msg}
        else:
            debug_info.append("[output_block] row_affected>0 => letting LLM message stand.")
            return {"final_answer": llm_message}

    if row_count is not None:
        if row_count == 0:
            final_msg = "No matching items found."
            debug_info.append("[output_block] SELECT => 0 => overriding.")
            return {"final_answer": final_msg}
        else:
            debug_info.append("[output_block] SELECT => letting LLM stand.")
            return {"final_answer": llm_message}

    debug_info.append("[output_block] letting LLM stand => no row_affected, row_count, or rows_inserted.")
    return {"final_answer": llm_message}

--- schemas.py ---
# backend/agent/schemas.py

from typing import List, Optional, Literal, Any
from pydantic import BaseModel

#
# 1) plan_tasks
#
class PlanTaskItem(BaseModel):
    block: str
    description: str
    title: str
    reasoning: str = ""

class PlanTasksArguments(BaseModel):
    tasks: List[PlanTaskItem]

plan_tasks_schema = {
    "name": "plan_tasks",
    "description": (
        "Produce a short plan (a list of tasks) to solve the user request. "
        "Each item has a block name, description, title, and reasoning."
    ),
    "parameters": PlanTasksArguments.schema()
}

#
# 2) sql_block
#
class SQLBlockArguments(BaseModel):
    table_name: str
    columns: List[str]  # e.g. ["name","quantity","unit","expiration_date","category"]
    values: List[str]   # e.g. ["'Joghurt'","2","'unit'","'2025-01-25'","'dairy'"]
    action_type: Literal["SELECT", "INSERT", "UPDATE", "DELETE"]
    explanation: str = ""
    where_clause: Optional[str] = None  # for updates/deletes

sql_block_schema = {
    "name": "sql_block",
    "description": (
        "Use this to run a SQL query on the local DB. "
        "No single big sql string—use 'table_name','columns','values','action_type','explanation'. "
        "No disclaimers or code blocks—only valid JSON."
    ),
    "parameters": {
        "type": "object",
        "properties": {
            "table_name": {"type": "string"},
            "columns": {
                "type": "array",
                "items": {"type": "string"}
            },
            "values": {
                "type": "array",
                "items": {"type": "string"}
            },
            "action_type": {
                "type": "string",
                "enum": ["SELECT","INSERT","UPDATE","DELETE"]
            },
            "explanation": {"type": "string"},
            "where_clause": {
                "type": "string",
                "description": "e.g. WHERE name='tomatoes'"
            }
        },
        "required": ["table_name","columns","values","action_type"],
        "additionalProperties": False
    }
}

#
# 3) output_block
#
class OutputBlockArguments(BaseModel):
    final_message: str

output_block_schema = {
    "name": "output_block",
    "description": "Produces the final user-facing answer as JSON with 'final_message'.",
    "parameters": {
        "type": "object",
        "properties": {
            "final_message": {
                "type": "string",
                "description": "User-facing text or summary"
            }
        },
        "required": ["final_message"],
        "additionalProperties": False
    }
}

#
# 4) parse_block
#
class ParseBlockArguments(BaseModel):
    raw_text: str
    explanation: Optional[str] = ""
    parsed_item: Optional[Any] = None
    # NEW: allow the LLM to pass db_rows if it wants
    db_rows: Optional[List[Any]] = None

parse_block_schema = {
    "name": "parse_block",
    "description": (
        "Parse or unify raw user text AND optionally DB data (db_rows) into a 'parsed_item'. "
        "No disclaimers, just JSON with 'raw_text', 'parsed_item', and optionally 'db_rows'."
    ),
    "parameters": {
        "type": "object",
        "properties": {
            "raw_text": {"type": "string"},
            "explanation": {"type": "string"},
            "parsed_item": {
                "type": "object",
                "description": "structured object if needed"
            },
            "db_rows": {
                "type": "array",
                "items": {"type": "object"},
                "description": "If we need to parse/fill data from a prior SELECT query"
            }
        },
        "required": ["raw_text"],
        "additionalProperties": False
    }
}

#
# 5) batch_insert_block
#
class BatchInsertRow(BaseModel):
    columns: List[str]
    values: List[str]

class BatchInsertBlockArguments(BaseModel):
    table_name: str
    rows: List[BatchInsertRow]
    explanation: str = ""

batch_insert_block_schema = {
    "name": "batch_insert_block",
    "description": (
        "Insert multiple rows into one table in a single call. "
        "No disclaimers, only valid JSON. "
        "If user says 'Add multiple items at once', produce an array of {columns, values}."
    ),
    "parameters": {
        "type": "object",
        "properties": {
            "table_name": {"type": "string"},
            "rows": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "columns": {
                            "type": "array",
                            "items": {"type": "string"}
                        },
                        "values": {
                            "type": "array",
                            "items": {"type": "string"}
                        }
                    },
                    "required": ["columns","values"]
                }
            },
            "explanation": {"type": "string"}
        },
        "required": ["table_name","rows"],
        "additionalProperties": False
    }
}

ALL_FUNCTION_SCHEMAS = [
    plan_tasks_schema,
    sql_block_schema,
    output_block_schema,
    parse_block_schema,
    batch_insert_block_schema
]

--- plan_prompt.md ---
You are an AI Orchestrator. You must produce a short plan (a list of tasks) in JSON form, calling the `plan_tasks` function.

We have these blocks you can use:

1) **sql_block**
   - Purpose: Run an actual SQL query on the local database.
   - You must produce JSON with `"table_name"`, `"columns"`, `"values"`, `"action_type"`, and `"explanation"`.
   - **Important:** For `fridge_items`, the valid columns are exactly: `"name", "quantity", "unit", "expiration_date", "category"`.
     No other columns like `"item_name"` or `"expiry_date"`.
   - We can do `SELECT`, `INSERT`, `UPDATE`, or `DELETE`. 
   - No disclaimers or code blocks—only function-calling with `"name": "sql_block"`.

2) **output_block**
   - Purpose: Provide the final user answer.

3) **parse_block**
   - Purpose: Parse or unify user text **and/or** data from the DB (if you have it) into structured form.
   - No disclaimers—only function-calling with `"name": "parse_block"`.

4) **batch_insert_block** (NEW)
   - Purpose: Insert multiple rows in a single call. 
   - If user says “Add these 5 items at once,” produce something like:
     ```json
     {
       "name": "batch_insert_block",
       "arguments": {
         "table_name":"fridge_items",
         "rows": [
           { "columns":["name","quantity"], "values":["milk","2"] },
           { "columns":["name","quantity"], "values":["eggs","12"] }
         ],
         "explanation":"User wants to add multiple items quickly"
       }
     }
     ```
   - No disclaimers.

**Constraints**:
- Return exactly **one** function call to `"plan_tasks"` with `"tasks": [...]`.
- Each task is an object: 
  ```json
  {
    "block": "sql_block" | "parse_block" | "output_block" | "batch_insert_block",
    "description": "...",
    "title": "...",
    "reasoning": "..."
  }
  - No extra text. At the final step, do NOT produce normal text—only output_block with {"final_message":"..."}.
Example of a more advanced scenario:
If user wants: “Retrieve fridge content, parse it, then update missing columns,” produce tasks like:
{
  "name": "plan_tasks",
  "arguments": {
    "tasks": [
      {
        "block": "sql_block",
        "description": "Select from fridge_items to get current data",
        "title": "Select Fridge",
        "reasoning": "We need existing rows"
      },
      {
        "block": "parse_block",
        "description": "Parse or unify the DB rows to fill missing columns",
        "title": "Parse DB rows",
        "reasoning": "User wants to fill missing data"
      },
      {
        "block": "sql_block",
        "description": "Update fridge with the newly filled columns",
        "title": "Update fridge",
        "reasoning": "We apply the parsed data to the DB"
      },
      {
        "block": "output_block",
        "description": "Return final answer",
        "title": "Show final answer",
        "reasoning": "We produce final text"
      }
    ]
  }
}
No disclaimers. Just that function call in valid JSON.