=== SYSTEM PROMPT ===
You are ChatGPT, a helpful developer assistant. You have been provided with a subset of files from the Jarvis project. Use this context for answering any user questions about the code. Do not reveal sensitive information or partial content that was not provided.

=== FOLDER STRUCTURE (SELECTED) ===
v0.2/
    backend/
        agent/
            orchestrator.py
            blocks.py
            schemas.py
            prompts/
                plan_prompt.md

=== FILE CONTENTS ===

--- orchestrator.py ---
# agent/orchestrator.py

import json
import os
import logging
import openai

from openai import OpenAI

from .schemas import ALL_FUNCTION_SCHEMAS, PlanTasksArguments
from .blocks import (
    handle_parse_block,
    handle_sql_block,
    handle_output_block,
    handle_batch_insert_block,
    handle_batch_update_block,
    handle_batch_delete_block,  # <-- also import the new delete handler
)
from agent.global_store import TABLE_SCHEMAS, CURRENT_DATETIME_FN

logger = logging.getLogger("agent")


def call_openai_plan(user_request: str, debug_info: list, task_memory: dict) -> PlanTasksArguments:
    """
    Calls GPT with plan instructions to produce a short JSON plan { tasks: [...] }.
    """
    base_dir = os.path.dirname(os.path.abspath(__file__))
    plan_path = os.path.join(base_dir, "prompts", "plan_prompt.md")
    with open(plan_path, "r", encoding="utf-8") as f:
        plan_instructions = f.read()

    model_name = task_memory.get("agent_model", "gpt-4-0613")

    messages = [
        {"role": "system", "content": plan_instructions},
        {"role": "user", "content": f"USER REQUEST: {user_request}"}
    ]

    logger.info(f"[call_openai_plan] user_request='{user_request}'")
    debug_info.append(f"[plan] user_request='{user_request}'")

    client = OpenAI(api_key=openai.api_key)
    resp = client.chat.completions.create(
        model=model_name,
        messages=messages,
        functions=[fn for fn in ALL_FUNCTION_SCHEMAS if fn["name"] == "plan_tasks"],
        function_call="auto",
        temperature=0.7
    )

    logger.info(f"[call_openai_plan] raw response => {resp}")
    debug_info.append(f"[plan] raw response => {resp}")

    choice = resp.choices[0]
    fn_call = choice.message.function_call
    if fn_call:
        fn_args_str = fn_call.arguments
        debug_info.append(f"[plan] function_call arguments => {fn_args_str}")
        try:
            data = json.loads(fn_args_str)
            plan_args = PlanTasksArguments(**data)
            logger.info(f"[call_openai_plan] Final plan => {plan_args.tasks}")
            debug_info.append(f"[plan] tasks => {plan_args.tasks}")
            return plan_args
        except Exception as e:
            debug_info.append(f"[plan] parse error => {e}")
            logger.warning(f"[call_openai_plan] parse error => {e}")
            return PlanTasksArguments(tasks=[])
    else:
        # fallback parse if no function_call
        content_str = choice.message.content or ""
        debug_info.append(f"[plan] no function_call, content => {content_str}")
        try:
            candidate = json.loads(content_str)
            if "name" in candidate and "arguments" in candidate:
                plan_args_data = candidate["arguments"]
                plan_args = PlanTasksArguments(**plan_args_data)
                logger.info(f"[call_openai_plan] Final plan => {plan_args.tasks}")
                debug_info.append(f"[plan] tasks => {plan_args.tasks}")
                return plan_args
        except:
            pass
        logger.info("[call_openai_plan] no tasks returned.")
        return PlanTasksArguments(tasks=[])


def build_system_prompt_for_block(block_name: str, block_description: str, task_memory: dict) -> str:
    """
    Provide specialized instructions for each block.
    Now also handle batch_insert_block, batch_update_block, and batch_delete_block
    with short schema notes. And mention parse_block can parse DB rows if needed.
    """
    from agent.global_store import TABLE_SCHEMAS, CURRENT_DATETIME_FN

    if block_name == "parse_block":
        user_req = task_memory.get("original_user_input", "")
        date_str = ""
        if CURRENT_DATETIME_FN:
            dt_now = CURRENT_DATETIME_FN()
            date_str = f"Current date/time => {dt_now.isoformat()}\n"

        target_table = task_memory.get("target_table", "(none)")
        table_cols = TABLE_SCHEMAS.get(target_table, [])
        col_list_str = ", ".join(table_cols)

        last_rows = task_memory.get("last_sql_rows", [])
        last_rows_str = json.dumps(last_rows, default=str)

        return (
            "You are the 'parse_block'. You can parse or unify user text AND/OR data from the DB.\n"
            "If 'db_rows' is provided, unify or fill columns. If user says '1 liter', parse quantity=1.0, unit='liter'.\n"
            "If user says 'expires next week', convert to a date offset.\n"
            "Return function_call => { raw_text:'...', explanation:'...', db_rows:..., parsed_item:{...} }.\n\n"
            f"{date_str}"
            f"Target table => {target_table}\n"
            f"Columns => {col_list_str}\n"
            f"last_sql_rows => {last_rows_str}\n"
            f"user_input => {user_req}\n"
            f"task_memory => {json.dumps(task_memory, default=str)}"
        )

    elif block_name == "sql_block":
        db_schema_str = (
            "Here is your DB schema:\n"
            "- fridge_items:\n"
            "   columns => [id, name, quantity, unit, expiration_date, category] (ALWAYS_ALLOW)\n"
            "- shopping_items:\n"
            "   columns => [id, name, desired_quantity, unit, purchased] (ALWAYS_ALLOW)\n"
            "- invoices:\n"
            "   columns => [id, date, total_amount, store_name] (REQUIRE_USER)\n"
            "- invoice_items:\n"
            "   columns => [id, invoice_id, name, quantity, price_per_unit] (REQUIRE_USER)\n"
            "- monthly_spendings:\n"
            "   columns => [id, year_month, total_spent] (ALWAYS_DENY)\n"
        )
        return (
            "You are 'sql_block'. You produce JSON => { table_name, columns, values, action_type, explanation, [where_clause] }.\n"
            "If user says 'delete X', do DELETE with a proper where_clause.\n"
            "If user says 'update X', do UPDATE with a proper where_clause.\n"
            "You MUST always provide a where_clause if action_type=DELETE or UPDATE.\n\n"
            + db_schema_str
            + "\n"
            + "task_memory => "
            + json.dumps(task_memory, default=str)
        )

    elif block_name == "output_block":
        last_sql = task_memory.get("last_sql_block_result", {})
        return (
            "You are 'output_block'. Summarize or finalize the answer.\n"
            "Override if rowcount=0 => say 'No items found or changed', or if there's an error.\n"
            f"last_sql_block_result => {json.dumps(last_sql, default=str)}\n"
            f"task_memory => {json.dumps(task_memory, default=str)}"
        )

    elif block_name == "batch_insert_block":
        db_schema_str = (
            "Here is your DB schema:\n"
            "- fridge_items:\n"
            "   columns => [id, name, quantity, unit, expiration_date, category] (ALWAYS_ALLOW)\n"
            "- shopping_items:\n"
            "   columns => [id, name, desired_quantity, unit, purchased] (ALWAYS_ALLOW)\n"
            "- invoices:\n"
            "   columns => [id, date, total_amount, store_name] (REQUIRE_USER)\n"
            "- invoice_items:\n"
            "   columns => [id, invoice_id, name, quantity, price_per_unit] (REQUIRE_USER)\n"
            "- monthly_spendings:\n"
            "   columns => [id, year_month, total_spent] (ALWAYS_DENY)\n"
        )
        return (
            "You are 'batch_insert_block'. You receive { table_name, rows:[{columns, values},...], explanation}.\n"
            "Insert multiple rows into the DB.\n\n"
            + db_schema_str
            + "\n"
            + "task_memory => "
            + json.dumps(task_memory, default=str)
        )

    elif block_name == "batch_update_block":
        db_schema_str = (
            "Here is your DB schema:\n"
            "- fridge_items:\n"
            "   columns => [id, name, quantity, unit, expiration_date, category] (ALWAYS_ALLOW)\n"
            "- shopping_items:\n"
            "   columns => [id, name, desired_quantity, unit, purchased] (ALWAYS_ALLOW)\n"
            "- invoices:\n"
            "   columns => [id, date, total_amount, store_name] (REQUIRE_USER)\n"
            "- invoice_items:\n"
            "   columns => [id, invoice_id, name, quantity, price_per_unit] (REQUIRE_USER)\n"
            "- monthly_spendings:\n"
            "   columns => [id, year_month, total_spent] (ALWAYS_DENY)\n"
        )
        return (
            "You are 'batch_update_block'. You receive { table_name, rows:[{where_clause, columns, values},...], explanation}.\n"
            "Update multiple rows in a single call. If user says 'Update these items at once,' produce multiple row objects.\n\n"
            + db_schema_str
            + "\n"
            + "task_memory => "
            + json.dumps(task_memory, default=str)
        )

    elif block_name == "batch_delete_block":  # <--- NEW
        db_schema_str = (
            "Here is your DB schema:\n"
            "- fridge_items:\n"
            "   columns => [id, name, quantity, unit, expiration_date, category] (ALWAYS_ALLOW)\n"
            "- shopping_items:\n"
            "   columns => [id, name, desired_quantity, unit, purchased] (ALWAYS_ALLOW)\n"
            "- invoices:\n"
            "   columns => [id, date, total_amount, store_name] (REQUIRE_USER)\n"
            "- invoice_items:\n"
            "   columns => [id, invoice_id, name, quantity, price_per_unit] (REQUIRE_USER)\n"
            "- monthly_spendings:\n"
            "   columns => [id, year_month, total_spent] (ALWAYS_DENY)\n"
        )
        return (
            "You are 'batch_delete_block'. You receive { table_name, rows:[{where_clause}], explanation}.\n"
            "Delete multiple rows in a single call. If user says 'Remove these items at once,' produce multiple row objects.\n"
            "Each object must have 'where_clause', e.g. WHERE id=7 or WHERE name='spinach'.\n\n"
            + db_schema_str
            + "\n"
            + "task_memory => "
            + json.dumps(task_memory, default=str)
        )

    else:
        return f"You are block={block_name}, partial memory => {json.dumps(task_memory, default=str)}"


def call_block_llm(block_name: str, block_description: str, task_memory: dict, debug_info: list):
    """
    Calls GPT with the appropriate function schema.
    Then dispatches to the matching handler: parse_block, sql_block, etc.
    """
    logger.info(f"[call_block_llm] block={block_name}, desc={block_description}")
    debug_info.append(f"[block_llm] block={block_name}, desc={block_description}")

    schema = None
    for s in ALL_FUNCTION_SCHEMAS:
        if s["name"] == block_name:
            schema = s
            break

    if not schema:
        msg = f"No schema found for block={block_name}"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}

    system_prompt = build_system_prompt_for_block(block_name, block_description, task_memory)
    model_name = task_memory.get("agent_model", "gpt-4-0613")

    client = OpenAI(api_key=openai.api_key)
    resp = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": block_description}
        ],
        functions=[schema],
        function_call="auto",
        temperature=0.7
    )
    logger.info(f"[call_block_llm] LLM resp => {resp}")
    debug_info.append(f"[block_llm] raw response => {resp}")

    choice = resp.choices[0]
    fn_call = choice.message.function_call
    if not fn_call:
        content_str = choice.message.content or ""
        debug_info.append(f"[block_llm] no function_call => fallback parse content = {content_str}")
        try:
            candidate = json.loads(content_str)
            if "name" in candidate and "arguments" in candidate:
                fallback_args = candidate["arguments"]
                logger.info(f"[call_block_llm] fallback parse => block={block_name}, arguments={fallback_args}")
                return dispatch_block(block_name, fallback_args, task_memory, debug_info)
        except Exception as e:
            msg = f"No function_call returned, fallback parse error => {e}"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        return {"error": "No function_call returned and fallback parse didn't match block."}
    else:
        fn_args_str = fn_call.arguments
        debug_info.append(f"[block_llm] function_call args => {fn_args_str}")
        logger.info(f"[call_block_llm] function_call args => {fn_args_str}")
        try:
            args_data = json.loads(fn_args_str)
        except Exception as e:
            debug_info.append(f"[block_llm] JSON parse error => {e}")
            return {"error": f"JSON parse error => {e}"}
        return dispatch_block(block_name, args_data, task_memory, debug_info)


def dispatch_block(block_name: str, args_data: dict, task_memory: dict, debug_info: list):
    logger.info(f"[dispatch_block] block={block_name}, args={args_data}")
    debug_info.append(f"[dispatch_block] block={block_name}, args={args_data}")

    # If the block is a DB-related batch or single SQL, set target_table from the arguments
    if ("table_name" in args_data
        and block_name in ["sql_block","batch_insert_block","batch_update_block","batch_delete_block"]):
        guessed_table = args_data["table_name"]
        debug_info.append(f"[dispatch_block] Setting target_table => {guessed_table}")
        task_memory["target_table"] = guessed_table

    from .blocks import (
        handle_parse_block,
        handle_sql_block,
        handle_output_block,
        handle_batch_insert_block,
        handle_batch_update_block,
        handle_batch_delete_block,
    )

    if block_name == "parse_block":
        return handle_parse_block(args_data, task_memory, debug_info)
    elif block_name == "sql_block":
        return handle_sql_block(args_data, task_memory, debug_info)
    elif block_name == "output_block":
        return handle_output_block(args_data, task_memory, debug_info)
    elif block_name == "batch_insert_block":
        return handle_batch_insert_block(args_data, task_memory, debug_info)
    elif block_name == "batch_update_block":
        return handle_batch_update_block(args_data, task_memory, debug_info)
    elif block_name == "batch_delete_block":  # <-- NEW
        return handle_batch_delete_block(args_data, task_memory, debug_info)
    else:
        msg = f"Unrecognized block => {block_name}"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}


def run_agent(user_input: str, initial_task_memory: dict = None):
    """
    Orchestrates the user request -> plan -> block calls -> final answer.
    """
    debug_info = []
    if not initial_task_memory:
        initial_task_memory = {}
    task_memory = {"original_user_input": user_input, **initial_task_memory}

    plan_result = call_openai_plan(user_input, debug_info, task_memory)
    if not plan_result.tasks:
        return ("Could not plan tasks. Possibly clarify your request.", debug_info)

    final_answer = "(No final answer produced)"
    output_block_triggered = False

    # Execute each step in the plan
    for step in plan_result.tasks:
        block = step.block
        desc = step.description

        # (Optional) guess table from step description, e.g. if it mentions "fridge_items"
        if "fridge_items" in desc.lower():
            task_memory["target_table"] = "fridge_items"
        elif "shopping_list" in desc.lower() or "shopping_items" in desc.lower():
            task_memory["target_table"] = "shopping_items"
        elif "invoice" in desc.lower():
            task_memory["target_table"] = "invoices"

        result = call_block_llm(block, desc, task_memory, debug_info)
        task_memory[f"last_{block}_result"] = result

        if block == "output_block":
            output_block_triggered = True
            # The output_block should produce either "final_answer" or "final_message"
            if "final_answer" in result:
                final_answer = result["final_answer"]
            else:
                fm = result.get("final_message", "")
                if fm:
                    final_answer = fm
            break

    # Fallback if there's no output_block
    if not output_block_triggered:
        last_sql_res = task_memory.get("last_sql_block_result", {})
        if "error" in last_sql_res:
            final_answer = "Sorry, an error occurred with your request:\n" + last_sql_res["error"]
        else:
            ra = last_sql_res.get("rows_affected", None)
            rc = last_sql_res.get("rows_count", None)
            rows_inserted = last_sql_res.get("rows_inserted", None)

            if rows_inserted is not None:
                if rows_inserted == 0:
                    final_answer = "No rows were inserted (possible mismatch)."
                else:
                    final_answer = f"Successfully inserted {rows_inserted} rows."
            elif ra is not None:
                if ra == 0:
                    final_answer = "No matching items were found to update/delete."
                else:
                    final_answer = "Success. The DB was updated."
            elif rc is not None:
                if rc == 0:
                    final_answer = "No items found."
                else:
                    final_answer = f"Found {rc} item(s)."
            else:
                final_answer = "Operation completed, but no final output_block was produced."

    return (final_answer, debug_info)

--- blocks.py ---
# agent/blocks.py

import re
import json
import logging
from typing import Any, Dict
from database import SessionLocal, table_permissions
from sqlalchemy import text
import datetime

logger = logging.getLogger("agent")

NAME_SYNONYMS = {
    "tomato": "tomatoes",
    "tomatoe": "tomatoes",
    "tomatoes": "tomatoes",
    # ...
}

DATE_SYNONYMS = {
    "today": 0,
    "tomorrow": 1,
    "next week": 7,
    # ...
}

def dictionary_normalize_item_name(raw: str) -> str:
    lowered = raw.strip().lower()
    return NAME_SYNONYMS.get(lowered, lowered)

def guess_quantity_and_unit_from_text(text: str) -> (float, str):
    match = re.search(
        r"(\d+(?:\.\d+)?)\s*(liter|liters|unit|units|bag|bags|piece|pieces)\b",
        text,
        re.IGNORECASE
    )
    if match:
        qty_str = match.group(1)
        unit_str = match.group(2)
        try:
            qty_val = float(qty_str)
        except:
            qty_val = 1.0
        return (qty_val, unit_str.lower())
    else:
        return (None, None)

def guess_expiration_date_from_text(text: str, current_dt_fn):
    match = re.search(r"(expires|expiring|expiry)\s+(today|tomorrow|next week)\b", text, re.IGNORECASE)
    if match:
        phrase = match.group(2).lower()
        offset_days = DATE_SYNONYMS.get(phrase, 0)
        now_dt = current_dt_fn() if current_dt_fn else datetime.datetime.utcnow()
        real_dt = now_dt + datetime.timedelta(days=offset_days)
        return real_dt.strftime("%Y-%m-%d")
    else:
        return None


def handle_parse_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    """
    parse_block can parse raw_text from user, but also can unify 'db_rows' if provided.
    We store the result in parsed_item or we can store additional logic.
    """
    raw_text = args.get("raw_text", "")
    explanation = args.get("explanation", "")
    parsed_item = args.get("parsed_item", {}) or {}

    # Optionally, if we have db_rows in the parse_block arguments:
    db_rows = args.get("db_rows", [])  # new field if you let LLM produce it

    debug_info.append(f"[parse_block] raw_text={raw_text}, explanation={explanation}, #db_rows={len(db_rows)}")

    from agent.global_store import TABLE_SCHEMAS, CURRENT_DATETIME_FN

    # Possibly unify synonyms if 'name' in parsed_item
    if "name" in parsed_item:
        old_name = parsed_item["name"]
        new_name = dictionary_normalize_item_name(old_name)
        parsed_item["name"] = new_name
        debug_info.append(f"[parse_block] Normalized name from '{old_name}' => '{new_name}'")

    # If no 'quantity' or 'unit', guess from raw_text
    if "quantity" not in parsed_item or "unit" not in parsed_item:
        (qty_guess, unit_guess) = guess_quantity_and_unit_from_text(raw_text)
        if qty_guess is not None and "quantity" not in parsed_item:
            parsed_item["quantity"] = qty_guess
        if unit_guess is not None and "unit" not in parsed_item:
            parsed_item["unit"] = unit_guess

    # If no expiration_date, guess from raw_text
    if "expiration_date" not in parsed_item:
        dt_guess = guess_expiration_date_from_text(raw_text, CURRENT_DATETIME_FN)
        if dt_guess:
            parsed_item["expiration_date"] = dt_guess

    # If we want to unify partial DB data as well
    # e.g. fill missing columns in each row, or something advanced.
    # For now, we just store the db_rows in memory so the LLM knows it can use them.
    # Or we can do more advanced logic here.
    if db_rows:
        debug_info.append(f"[parse_block] We also have {len(db_rows)} row(s) from the DB to parse/unify.")
        # In a real scenario, you might unify each row with parsed_item
        # or do some advanced merging logic. For now, we just keep them in memory:
        task_memory["last_parsed_db_rows"] = db_rows

    # Also fill missing columns if target_table is known
    target_table = task_memory.get("target_table", "")
    col_list = TABLE_SCHEMAS.get(target_table, [])
    debug_info.append(f"[parse_block] target_table => {target_table}, col_list => {col_list}")

    for c in col_list:
        if c not in parsed_item:
            if c == "quantity":
                parsed_item[c] = 1.0
            elif c == "unit":
                parsed_item[c] = "unit"
            elif c == "expiration_date":
                parsed_item[c] = None
            elif c == "category":
                parsed_item[c] = "misc"

    debug_info.append(f"[parse_block] final parsed_item => {parsed_item}")
    task_memory["parsed_item"] = parsed_item

    return {
        "success": True,
        "parsed_item": parsed_item,
        "db_rows": db_rows,
        "explanation": explanation
    }


def build_case_insensitive_where(where_str: str) -> str:
    pattern = r"(?i)WHERE\s+name\s*=\s*([\"'])(.*?)\1"
    replacement = r"WHERE LOWER(name)=LOWER(\1\2\1)"
    out = re.sub(pattern, replacement, where_str)
    return out

def quote_if_needed(val: str) -> str:
    # If val is None, treat it as "NULL" in SQL
    if val is None:
        return "NULL"

    # else proceed
    trimmed = val.strip()
    # if numeric or already single-quoted => return as is
    if (trimmed.startswith("'") and trimmed.endswith("'")) or trimmed.replace(".", "", 1).isdigit():
        return trimmed

    return f"'{trimmed}'"


def handle_sql_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    """
    The normal single SQL action: SELECT, INSERT, UPDATE, DELETE.
    Potentially merges parse_block data into columns/values if action_type in [INSERT,UPDATE].
    """
    table_name = args.get("table_name", "").strip()
    columns = args.get("columns", [])
    values = args.get("values", [])
    action_type = args.get("action_type", "").upper()
    explanation = args.get("explanation", "")
    where_clause = args.get("where_clause", "").strip()

    debug_info.append(
        f"[sql_block] user gave => table={table_name}, cols={columns}, vals={values}, "
        f"action={action_type}, where={where_clause}"
    )

    parsed_item = task_memory.get("parsed_item", {})
    if parsed_item and action_type in ["INSERT","UPDATE"]:
        for col, val in parsed_item.items():
            if col not in columns:
                columns.append(col)
                val_str = "NULL" if val is None else str(val)
                values.append(val_str)
        debug_info.append(f"[sql_block] after merging parse_item => columns={columns}, values={values}")

    permission_mode = table_permissions.get(table_name, "ALWAYS_DENY")
    user_permission = True

    if action_type == "SELECT":
        if permission_mode == "ALWAYS_DENY":
            msg = f"[sql_block] SELECT on '{table_name}' => ALWAYS_DENY"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        col_list_str = "*"
        if columns:
            col_list_str = ", ".join(columns)
        sql_query = f"SELECT {col_list_str} FROM {table_name};"
        return run_select_query(sql_query, explanation, debug_info, task_memory)

    elif action_type == "INSERT":
        if permission_mode == "ALWAYS_DENY":
            msg = f"[sql_block] INSERT => table '{table_name}' => ALWAYS_DENY"
            debug_info.append(msg)
            return {"error": msg}

        if len(columns) != len(values):
            msg = f"[sql_block] Mismatch => columns={columns}, values={values}"
            debug_info.append(msg)
            return {"error": msg}

        col_list_str = ", ".join(columns)
        val_list_str = ", ".join(quote_if_needed(v) for v in values)
        sql_query = f"INSERT INTO {table_name}({col_list_str}) VALUES({val_list_str});"
        debug_info.append(f"[sql_block] final INSERT => {sql_query}")
        return run_write_query(sql_query, explanation, debug_info)

    elif action_type in ["UPDATE","DELETE"]:
        if permission_mode == "ALWAYS_DENY":
            msg = f"[sql_block] Writes to '{table_name}' => ALWAYS_DENY"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        if permission_mode == "REQUIRE_USER" and not user_permission:
            msg = f"[sql_block] Write to '{table_name}' => not granted"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        if not where_clause.upper().startswith("WHERE"):
            msg = f"[sql_block] {action_type} requested but no where_clause => not allowed!"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        ci_where = build_case_insensitive_where(where_clause)
        debug_info.append(f"[sql_block] transformed where => {ci_where}")
        where_clause = ci_where

        if action_type == "UPDATE":
            if len(columns) != len(values):
                msg = f"[sql_block] mismatch col vs val => {columns} vs {values}"
                debug_info.append(msg)
                return {"error": msg}
            set_clauses = []
            for c, v in zip(columns, values):
                set_clauses.append(f"{c}={quote_if_needed(v)}")
            set_stmt = ", ".join(set_clauses)
            sql_query = f"UPDATE {table_name} SET {set_stmt} {where_clause};"
            debug_info.append(f"[sql_block] final UPDATE => {sql_query}")
            return run_write_query(sql_query, explanation, debug_info)

        elif action_type == "DELETE":
            sql_query = f"DELETE FROM {table_name} {where_clause};"
            debug_info.append(f"[sql_block] final DELETE => {sql_query}")
            return run_write_query(sql_query, explanation, debug_info)

    else:
        msg = f"[sql_block] unrecognized action_type={action_type}"
        debug_info.append(msg)
        return {"error": msg}


def run_select_query(sql_query: str, explanation: str, debug_info: list, task_memory: dict) -> dict:
    db = SessionLocal()
    rows_data = []
    error_msg = None
    try:
        debug_info.append(f"[sql_block] Running SELECT => {sql_query}")
        result = db.execute(text(sql_query))
        all_rows = result.fetchall()
        for row in all_rows:
            row_dict = dict(row._mapping)
            rows_data.append(row_dict)
        debug_info.append(f"[sql_block] SELECT => got {len(rows_data)} row(s)")
        logger.info(f"[sql_block] success => SELECT '{sql_query}', rows={len(rows_data)}")
    except Exception as e:
        error_msg = str(e)
        debug_info.append(f"[sql_block] select error => {error_msg}")
        logger.warning(f"[sql_block] SELECT error => {error_msg}")
    finally:
        db.close()

    if error_msg:
        return {"error": error_msg, "sql_query": sql_query}
    # Store the rows in memory so parse_block can read them
    task_memory["last_sql_rows"] = rows_data
    return {
        "success": True,
        "rows_data": rows_data,
        "explanation": explanation,
        "rows_count": len(rows_data)
    }

def run_write_query(sql_query: str, explanation: str, debug_info: list) -> dict:
    db = SessionLocal()
    error_msg = None
    rowcount = 0
    try:
        debug_info.append(f"[sql_block] Running WRITE => {sql_query}")
        result = db.execute(text(sql_query))
        rowcount = result.rowcount or 0
        db.commit()
        debug_info.append(f"[sql_block] WRITE => rowcount={rowcount}")
        logger.info(f"[sql_block] success => WRITE '{sql_query}', rowcount={rowcount}")
    except Exception as e:
        error_msg = str(e)
        debug_info.append(f"[sql_block] write error => {error_msg}")
        logger.warning(f"[sql_block] WRITE error => {error_msg}")
        db.rollback()
    finally:
        db.close()

    if error_msg:
        return {"error": error_msg, "sql_query": sql_query}
    return {
        "success": True,
        "rows_affected": rowcount,
        "explanation": explanation
    }

def handle_batch_insert_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    """
    Insert multiple rows into a table in one go.
    """
    table_name = args.get("table_name","").strip()
    rows_info = args.get("rows", [])
    explanation = args.get("explanation","")

    debug_info.append(f"[batch_insert] table={table_name}, #rows={len(rows_info)}")

    permission_mode = table_permissions.get(table_name, "ALWAYS_DENY")
    user_permission = True

    if permission_mode == "ALWAYS_DENY":
        msg = f"[batch_insert_block] INSERT => table '{table_name}' => ALWAYS_DENY"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}

    if permission_mode == "REQUIRE_USER" and not user_permission:
        msg = f"[batch_insert_block] Write to '{table_name}' => not granted"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}

    inserted_count = 0
    error_msg = None
    db = SessionLocal()
    try:
        for row_data in rows_info:
            columns = row_data.get("columns", [])
            values = row_data.get("values", [])

            if len(columns) != len(values):
                raise ValueError(f"Mismatch in columns vs. values => {columns} vs. {values}")

            col_list_str = ", ".join(columns)
            val_list_str = ", ".join(quote_if_needed(v) for v in values)
            sql_query = f"INSERT INTO {table_name} ({col_list_str}) VALUES ({val_list_str});"
            debug_info.append(f"[batch_insert] running => {sql_query}")

            result = db.execute(text(sql_query))
            rowcount = result.rowcount or 0
            inserted_count += rowcount

        db.commit()
    except Exception as e:
        error_msg = str(e)
        debug_info.append(f"[batch_insert] error => {error_msg}")
        logger.warning(f"[batch_insert_block] error => {error_msg}")
        db.rollback()
    finally:
        db.close()

    if error_msg:
        return {"error": error_msg, "rows_inserted": inserted_count, "explanation": explanation}

    return {
        "success": True,
        "rows_inserted": inserted_count,
        "explanation": explanation
    }

def handle_batch_update_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    """
    Similar to batch_insert_block, but for multiple UPDATE statements in one call.

    {
      "table_name": "fridge_items",
      "rows": [
        {
          "where_clause": "WHERE id=5",
          "columns": ["quantity","expiration_date"],
          "values": ["3","2025-05-10"]
        },
        ...
      ],
      "explanation": "some reason"
    }
    """
    table_name = args.get("table_name","").strip()
    rows_info = args.get("rows", [])
    explanation = args.get("explanation","")

    debug_info.append(f"[batch_update] table={table_name}, #rows={len(rows_info)}")

    permission_mode = table_permissions.get(table_name, "ALWAYS_DENY")
    user_permission = True  # or some real check

    if permission_mode == "ALWAYS_DENY":
        msg = f"[batch_update_block] => table '{table_name}' => ALWAYS_DENY"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}

    if permission_mode == "REQUIRE_USER" and not user_permission:
        msg = f"[batch_update_block] => not granted for '{table_name}'"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}

    updated_count = 0
    error_msg = None
    db = SessionLocal()
    try:
        for row_data in rows_info:
            where_clause = row_data.get("where_clause","").strip()
            columns = row_data.get("columns", [])
            values = row_data.get("values", [])

            if not where_clause.upper().startswith("WHERE"):
                raise ValueError(f"Missing or invalid where_clause => {where_clause}")

            if len(columns) != len(values):
                raise ValueError(f"Mismatch => columns={columns}, values={values}")

            set_clauses = []
            for c, v in zip(columns, values):
                set_clauses.append(f"{c}={quote_if_needed(v)}")
            set_stmt = ", ".join(set_clauses)

            sql_query = f"UPDATE {table_name} SET {set_stmt} {where_clause};"
            debug_info.append(f"[batch_update] running => {sql_query}")

            result = db.execute(text(sql_query))
            rowcount = result.rowcount or 0
            updated_count += rowcount

        db.commit()
    except Exception as e:
        error_msg = str(e)
        debug_info.append(f"[batch_update_block] error => {error_msg}")
        logger.warning(f"[batch_update_block] error => {error_msg}")
        db.rollback()
    finally:
        db.close()

    if error_msg:
        return {"error": error_msg, "rows_affected": updated_count, "explanation": explanation}

    return {
        "success": True,
        "rows_affected": updated_count,
        "explanation": explanation
    }

def handle_batch_delete_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    """
    Delete multiple rows in a table in one go.

    Example JSON:
    {
      "table_name": "fridge_items",
      "rows": [
        { "where_clause": "WHERE id=7" },
        { "where_clause": "WHERE name='spinach'" }
      ],
      "explanation": "Remove multiple items at once"
    }
    """
    table_name = args.get("table_name", "").strip()
    rows_info = args.get("rows", [])
    explanation = args.get("explanation", "")

    debug_info.append(f"[batch_delete_block] table={table_name}, #rows={len(rows_info)}")

    from database import table_permissions
    permission_mode = table_permissions.get(table_name, "ALWAYS_DENY")
    user_permission = True  # e.g. some real check eventually

    if permission_mode == "ALWAYS_DENY":
        msg = f"[batch_delete_block] => table '{table_name}' => ALWAYS_DENY"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}

    if permission_mode == "REQUIRE_USER" and not user_permission:
        msg = f"[batch_delete_block] => not granted for '{table_name}'"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}

    deleted_count = 0
    error_msg = None
    db = SessionLocal()

    try:
        for row_data in rows_info:
            where_clause = row_data.get("where_clause", "").strip()
            if not where_clause.upper().startswith("WHERE"):
                raise ValueError(f"Missing or invalid where_clause => {where_clause}")

            # Optionally convert to case-insensitive if needed
            final_where = build_case_insensitive_where(where_clause)

            sql_query = f"DELETE FROM {table_name} {final_where};"
            debug_info.append(f"[batch_delete_block] running => {sql_query}")

            result = db.execute(text(sql_query))
            rowcount = result.rowcount or 0
            deleted_count += rowcount

        db.commit()
    except Exception as e:
        error_msg = str(e)
        debug_info.append(f"[batch_delete_block] error => {error_msg}")
        logger.warning(f"[batch_delete_block] error => {error_msg}")
        db.rollback()
    finally:
        db.close()

    if error_msg:
        return {"error": error_msg, "rows_affected": deleted_count, "explanation": explanation}

    # re-use "rows_affected" so output_block logic can handle it
    return {
        "success": True,
        "rows_affected": deleted_count,
        "explanation": explanation
    }


def handle_output_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    llm_message = args.get("final_message", "").strip()
    if not llm_message:
        llm_message = "(No final_message provided by LLM)"

    last_sql_result = task_memory.get("last_sql_block_result", {})
    sql_error = last_sql_result.get("error", "")
    row_affected = last_sql_result.get("rows_affected", None)
    row_count = last_sql_result.get("rows_count", None)
    rows_inserted = last_sql_result.get("rows_inserted", None)

    if sql_error:
        final_msg = f"Sorry, an error occurred with your request:\n{sql_error}"
        debug_info.append("[output_block] Overriding LLM message due to SQL error.")
        return {"final_answer": final_msg}

    if rows_inserted is not None:
        if rows_inserted == 0:
            final_msg = "No rows were inserted. Possibly data mismatch or user canceled."
            debug_info.append("[output_block] Overriding LLM => no rows inserted.")
            return {"final_answer": final_msg}
        else:
            debug_info.append(f"[output_block] Inserted {rows_inserted} => letting LLM message stand.")
            return {"final_answer": llm_message}

    if row_affected is not None:
        if row_affected == 0:
            final_msg = (
                "No matching items were found to update/delete. "
                "If you expected a change, please check the name."
            )
            debug_info.append("[output_block] Overriding LLM => no row changed.")
            return {"final_answer": final_msg}
        else:
            debug_info.append("[output_block] row_affected>0 => letting LLM message stand.")
            return {"final_answer": llm_message}

    if row_count is not None:
        if row_count == 0:
            final_msg = "No matching items found."
            debug_info.append("[output_block] SELECT => 0 => overriding.")
            return {"final_answer": final_msg}
        else:
            debug_info.append("[output_block] SELECT => letting LLM stand.")
            return {"final_answer": llm_message}

    debug_info.append("[output_block] letting LLM stand => no row_affected, row_count, or rows_inserted.")
    return {"final_answer": llm_message}

--- schemas.py ---
# backend/agent/schemas.py

from typing import List, Optional, Literal, Any
from pydantic import BaseModel

#
# 1) plan_tasks
#
class PlanTaskItem(BaseModel):
    block: str
    description: str
    title: str
    reasoning: str = ""

class PlanTasksArguments(BaseModel):
    tasks: List[PlanTaskItem]

plan_tasks_schema = {
    "name": "plan_tasks",
    "description": (
        "Produce a short plan (a list of tasks) to solve the user request. "
        "Each item has a block name, description, title, and reasoning."
    ),
    "parameters": PlanTasksArguments.schema()
}

#
# 2) sql_block
#
class SQLBlockArguments(BaseModel):
    table_name: str
    columns: List[str]  # e.g. ["name","quantity","unit","expiration_date","category"]
    values: List[str]   # e.g. ["'Joghurt'","2","'unit'","'2025-01-25'","'dairy'"]
    action_type: Literal["SELECT", "INSERT", "UPDATE", "DELETE"]
    explanation: str = ""
    where_clause: Optional[str] = None  # for updates/deletes

sql_block_schema = {
    "name": "sql_block",
    "description": (
        "Use this to run a SQL query on the local DB. "
        "No single big sql string—use 'table_name','columns','values','action_type','explanation'. "
        "No disclaimers or code blocks—only valid JSON."
    ),
    "parameters": {
        "type": "object",
        "properties": {
            "table_name": {"type": "string"},
            "columns": {
                "type": "array",
                "items": {"type": "string"}
            },
            "values": {
                "type": "array",
                "items": {"type": "string"}
            },
            "action_type": {
                "type": "string",
                "enum": ["SELECT","INSERT","UPDATE","DELETE"]
            },
            "explanation": {"type": "string"},
            "where_clause": {
                "type": "string",
                "description": "e.g. WHERE name='tomatoes'"
            }
        },
        "required": ["table_name","columns","values","action_type"],
        "additionalProperties": False
    }
}

#
# 3) output_block
#
class OutputBlockArguments(BaseModel):
    final_message: str

output_block_schema = {
    "name": "output_block",
    "description": "Produces the final user-facing answer as JSON with 'final_message'.",
    "parameters": {
        "type": "object",
        "properties": {
            "final_message": {
                "type": "string",
                "description": "User-facing text or summary"
            }
        },
        "required": ["final_message"],
        "additionalProperties": False
    }
}

#
# 4) parse_block
#
class ParseBlockArguments(BaseModel):
    raw_text: str
    explanation: Optional[str] = ""
    parsed_item: Optional[Any] = None
    # NEW: allow the LLM to pass db_rows if it wants
    db_rows: Optional[List[Any]] = None

parse_block_schema = {
    "name": "parse_block",
    "description": (
        "Parse or unify raw user text AND optionally DB data (db_rows) into a 'parsed_item'. "
        "No disclaimers, just JSON with 'raw_text', 'parsed_item', and optionally 'db_rows'."
    ),
    "parameters": {
        "type": "object",
        "properties": {
            "raw_text": {"type": "string"},
            "explanation": {"type": "string"},
            "parsed_item": {
                "type": "object",
                "description": "structured object if needed"
            },
            "db_rows": {
                "type": "array",
                "items": {"type": "object"},
                "description": "If we need to parse/fill data from a prior SELECT query"
            }
        },
        "required": ["raw_text"],
        "additionalProperties": False
    }
}

#
# 5) batch_insert_block
#
class BatchInsertRow(BaseModel):
    columns: List[str]
    values: List[str]

class BatchInsertBlockArguments(BaseModel):
    table_name: str
    rows: List[BatchInsertRow]
    explanation: str = ""

batch_insert_block_schema = {
    "name": "batch_insert_block",
    "description": (
        "Insert multiple rows into one table in a single call. "
        "No disclaimers, only valid JSON. "
        "If user says 'Add multiple items at once', produce an array of {columns, values}."
    ),
    "parameters": {
        "type": "object",
        "properties": {
            "table_name": {"type": "string"},
            "rows": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "columns": {
                            "type": "array",
                            "items": {"type": "string"}
                        },
                        "values": {
                            "type": "array",
                            "items": {"type": "string"}
                        }
                    },
                    "required": ["columns","values"]
                }
            },
            "explanation": {"type": "string"}
        },
        "required": ["table_name","rows"],
        "additionalProperties": False
    }
}

class BatchUpdateRow(BaseModel):
    where_clause: str            # e.g. "WHERE id=6"
    columns: List[str]
    values: List[str]

class BatchUpdateBlockArguments(BaseModel):
    table_name: str
    rows: List[BatchUpdateRow]
    explanation: str = ""

batch_update_block_schema = {
    "name": "batch_update_block",
    "description": (
        "Update multiple rows in one table in a single call. "
        "If user says 'Update multiple fridge items at once', produce an array of row updates."
    ),
    "parameters": {
        "type": "object",
        "properties": {
            "table_name": {
                "type": "string",
                "description": "e.g. 'fridge_items'"
            },
            "rows": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "where_clause": {
                            "type": "string",
                            "description": "WHERE clause, e.g. 'WHERE id=7'"
                        },
                        "columns": {
                            "type": "array",
                            "items": {"type": "string"}
                        },
                        "values": {
                            "type": "array",
                            "items": {"type": "string"}
                        }
                    },
                    "required": ["where_clause","columns","values"]
                },
                "description": "List of row-level updates"
            },
            "explanation": {
                "type": "string",
                "description": "Reasoning or comment about these updates"
            }
        },
        "required": ["table_name","rows"],
        "additionalProperties": False
    }
}

class BatchDeleteRow(BaseModel):
    where_clause: str  # e.g. "WHERE id=5" or "WHERE name='spinach'"

class BatchDeleteBlockArguments(BaseModel):
    table_name: str
    rows: List[BatchDeleteRow]  # each row just has a where_clause
    explanation: str = ""

batch_delete_block_schema = {
    "name": "batch_delete_block",
    "description": (
        "Delete multiple rows from one table in a single call. "
        "If user says 'Remove these 5 items at once,' produce something like:\n"
        "{\n"
        '  "table_name": "fridge_items",\n'
        '  "rows": [\n'
        '     {"where_clause":"WHERE id=7"},\n'
        '     {"where_clause":"WHERE name=\'spinach\'"}\n'
        '   ],\n'
        '  "explanation":"Deleting multiple items at once."\n'
        '}'
    ),
    "parameters": {
        "type": "object",
        "properties": {
            "table_name": {
                "type": "string",
                "description": "The DB table to delete from, e.g. 'fridge_items'"
            },
            "rows": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "where_clause": {
                            "type": "string",
                            "description": "WHERE clause, e.g. 'WHERE name=\\'spinach\\''"
                        }
                    },
                    "required": ["where_clause"]
                },
                "description": "List of row-level deletes"
            },
            "explanation": {
                "type": "string",
                "description": "Reason or comment about these deletions"
            }
        },
        "required": ["table_name","rows"],
        "additionalProperties": False
    }
}

class ChatBlockArguments(BaseModel):
    user_prompt: str                 # The question or text the user (or system) wants to feed into chat
    context: Optional[str] = None    # If we have an optional large context

chat_block_schema = {
    "name": "chat_block",
    "description": (
        "Perform an open-ended chat or reasoning step. "
        "We supply 'user_prompt' plus optional 'context'. "
        "In response, produce text in 'response_text' if needed."
    ),
    "parameters": {
        "type": "object",
        "properties": {
            "user_prompt": {
                "type": "string",
                "description": "The user or system query we want to chat or reason about"
            },
            "context": {
                "type": "string",
                "description": "Optional large context or relevant background we want to feed the model"
            }
        },
        "required": ["user_prompt"],
        "additionalProperties": False
    }
}

ALL_FUNCTION_SCHEMAS = [
    plan_tasks_schema,
    sql_block_schema,
    output_block_schema,
    parse_block_schema,
    batch_insert_block_schema,
    batch_update_block_schema,
    batch_delete_block_schema,
    chat_block_schema
]

--- plan_prompt.md ---
You are an **AI Orchestrator**. Your job is to **produce exactly one JSON object** in the following shape:

```json
{
  "name": "plan_tasks",
  "arguments": {
    "tasks": [
      {
        "block": "...",
        "description": "...",
        "title": "...",
        "reasoning": "..."
      },
      ...
    ]
  }
}
No additional top-level JSON or text is allowed—only this single "plan_tasks" JSON object.

Tasks Array
Inside "arguments": { "tasks": [...] }, each element is a step with:
{
  "block": "<block_name>",
  "description": "<short explanation>",
  "title": "<short label>",
  "reasoning": "<brief reasoning>"
}
The final item in "tasks" must be {"block":"output_block", ...} with a "final_message":"...".

Blocks You Can Use:
1) sql_block

Purpose: Execute a single SQL query.
Must produce "table_name", "columns", "values", "action_type", "explanation".
Allowed action_type: "SELECT" | "INSERT" | "UPDATE" | "DELETE".
For the table fridge_items, valid columns are exactly [ "name", "quantity", "unit", "expiration_date", "category" ].
No disclaimers or code blocks; only JSON with "name":"sql_block".
2) parse_block

Purpose: Parse or unify user text and/or DB data into a more structured form.
Important: This does not do database changes. It only prepares data for a later step.
If the user’s request wants to physically change the DB, you must eventually produce sql_block or batch_update_block or batch_delete_block after parse_block. Don’t end on parse_block alone.
3) batch_insert_block

Purpose: Insert multiple rows in a single call.
For example:
{
  "name": "batch_insert_block",
  "arguments": {
    "table_name": "fridge_items",
    "rows": [
      { "columns": ["name","quantity"], "values": ["milk","2"] },
      { "columns": ["name","quantity"], "values": ["eggs","12"] }
    ],
    "explanation": "Multiple inserts"
  }
}

4) batch_update_block

Purpose: Update multiple rows in a single call.
If the user wants to physically change existing rows, produce a batch_update_block with where_clause for each row, for example:
{
  "name": "batch_update_block",
  "arguments": {
    "table_name": "fridge_items",
    "rows": [
      {
        "where_clause": "WHERE id=6",
        "columns": ["quantity","expiration_date"],
        "values": ["4","2025-07-01"]
      },
      {
        "where_clause": "WHERE id=7",
        "columns": ["quantity"],
        "values": ["2"]
      }
    ],
    "explanation": "Bulk update"
  }
}
No disclaimers. Provide each row’s where_clause, columns, and values.

5) batch_delete_block

Purpose: Delete multiple rows in a single call.
E.g.:
{
  "name": "batch_delete_block",
  "arguments": {
    "table_name": "fridge_items",
    "rows": [
      { "where_clause": "WHERE id=7" },
      { "where_clause": "WHERE name='spinach'" }
    ],
    "explanation": "Deleting multiple items"
  }
}

No disclaimers. Provide each row’s where_clause as needed.

6) output_block

Purpose: Provide the user-facing conclusion.
Must have {"final_message":"some text"}.
Always the final step in your "tasks" array.

Key Constraints:
Exactly one JSON object with "name":"plan_tasks" at top-level.
Inside: "arguments":{ "tasks":[...] }.
The final item in tasks must be {"block": "output_block", ...} with "final_message":"...".
If user’s request implies physically changing or removing items in the DB, do not finish with parse_block alone. You must produce an actual write step:
sql_block with "action_type":"UPDATE" or "action_type":"DELETE",
or batch_update_block,
or batch_delete_block.
Then finalize with output_block.

Remember:
parse_block is purely for reformatting or clarifying data. It does no actual database changes.
For changes, you need a sql_block or batch_..._block.

Available Table Names:
fridge_items
shopping_items
invoices
invoice_items
monthly_spendings

Example of a Multi-Step Plan:
{
  "name": "plan_tasks",
  "arguments": {
    "tasks": [
      {
        "block": "sql_block",
        "description": "Select from fridge_items",
        "title": "Query fridge",
        "reasoning": "We need existing rows"
      },
      {
        "block": "parse_block",
        "description": "Analyze retrieved data to find missing columns",
        "title": "Parse for missing data",
        "reasoning": "We unify or fill columns in memory"
      },
      {
        "block": "batch_update_block",
        "description": "Fix missing columns in fridge_items",
        "title": "Batch update fridge",
        "reasoning": "Apply the changes we decided on"
      },
      {
        "block": "output_block",
        "description": "Final user answer",
        "title": "Show result",
        "reasoning": "We provide final user-facing text"
      }
    ]
  }
}

(Where the final item is an output_block with "final_message":"...".)

No disclaimers, no extra JSON at the top level. Just the single {"name":"plan_tasks","arguments":{...}}.

That’s it—no other text.

### Additional Nudges

- If the user says “clean up / sanitize / fix duplicates / fill missing columns,” that implies a real DB **update** or **delete** step. So your plan must contain a `batch_update_block` or `batch_delete_block` or a `sql_block` with `"action_type":"UPDATE"`/`"DELETE"`.  
- Do **not** finalize with parse_block alone. The parse_block is only a “prep” step.  
- Always produce an **output_block** at the end with `"final_message":"some short user-facing text"`.  
