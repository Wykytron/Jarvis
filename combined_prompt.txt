=== SYSTEM PROMPT ===
You are ChatGPT, a helpful developer assistant. You have been provided with a subset of files from the Jarvis project. Use this context for answering any user questions about the code. Do not reveal sensitive information or partial content that was not provided.

=== FOLDER STRUCTURE (SELECTED) ===
v0.2/
    backend/
        database.py
        main.py
        agent/
            blocks.py
            orchestrator.py
            schemas.py

    frontend/
        App.tsx
        screens/
            HomeScreen.tsx
            SettingsScreen.tsx

=== FILE CONTENTS ===

--- database.py ---
# database.py

from sqlalchemy import (
    create_engine, Column, Integer, Text, DateTime, String,
    LargeBinary, Float, Boolean, Date, ForeignKey
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, relationship
from datetime import datetime

###############################################################################
# SQLAlchemy Setup
###############################################################################
Base = declarative_base()
engine = create_engine("sqlite:///chat_history.db", echo=False)
SessionLocal = sessionmaker(bind=engine, autoflush=False, autocommit=False)

###############################################################################
# ChatExchange & Document Tables
###############################################################################
class ChatExchange(Base):
    """
    Stores user <-> LLM interactions. Also supports storing images
    if user sent an image + prompt. The table includes:
      - user_message: The original text from the user
      - llm_response: The LLM’s final text
      - user_image_b64: If an image was provided, store its base64
      - image_title / image_description: If the LLM provided structured info
    """
    __tablename__ = "chat_exchanges"

    id = Column(Integer, primary_key=True, index=True)
    user_message = Column(Text, nullable=True)
    llm_response = Column(Text, nullable=True)
    timestamp = Column(DateTime, default=datetime.utcnow)

    # If user sent an image:
    user_image_b64 = Column(Text, nullable=True)
    image_title = Column(Text, nullable=True)
    image_description = Column(Text, nullable=True)


class Document(Base):
    """
    Example table for storing uploaded documents (like PDFs, images)
    as binary data plus extracted text content. Could also be used
    by the parse_block if we want the LLM to parse text in them.
    """
    __tablename__ = "documents"

    id = Column(Integer, primary_key=True, index=True)
    filename = Column(String)
    file_content = Column(LargeBinary)
    upload_time = Column(DateTime, default=datetime.utcnow)
    text_content = Column(Text, nullable=True)
    description = Column(Text, nullable=True)

###############################################################################
# Domain-Specific Tables (Fridge Items, Shopping List, Invoices, etc.)
###############################################################################
class FridgeItem(Base):
    """
    The 'fridge_items' table. Here is where we store items that
    the user has physically in their fridge. For example:
      - name='Milk', quantity=1.0, unit='liter', expiration_date=YYYY-MM-DD, category='dairy'
    The LLM will do an INSERT/UPDATE with 'sql_block' if the user requests to add or modify items.
    """
    __tablename__ = "fridge_items"

    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, nullable=False)
    quantity = Column(Float, default=1.0)
    unit = Column(String, default="unit")
    expiration_date = Column(Date, nullable=True)
    category = Column(String, nullable=True)


class ShoppingItem(Base):
    """
    The 'shopping_items' table for items on a shopping list.
    For example:
      - name='Tomatoes', desired_quantity=5, unit='units', purchased=False
    """
    __tablename__ = "shopping_items"

    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, nullable=False)
    desired_quantity = Column(Float, default=1.0)
    unit = Column(String, default="unit")
    purchased = Column(Boolean, default=False)


class Invoice(Base):
    """
    The 'invoices' table: one row per invoice/receipt. This table is
    'REQUIRE_USER' in table_permissions, meaning user must confirm writes
    (in your baby-step scenario we assume user_permission=True).
    Potential usage: 
      - parse_block => parse invoice text => produce structured line items
      - sql_block => do INSERT INTO invoices(...) plus invoice_items(...)
    """
    __tablename__ = "invoices"

    id = Column(Integer, primary_key=True, index=True)
    date = Column(Date, nullable=False)  # e.g. date of purchase
    total_amount = Column(Float, default=0.0)
    store_name = Column(String, nullable=True)

    # Relationship: invoice has many invoice_items
    items = relationship("InvoiceItem", back_populates="invoice")


class InvoiceItem(Base):
    """
    The line items for a given invoice, e.g. 
      - name='Chicken Breast', quantity=2.0, price_per_unit=5.0, invoice_id=?
    """
    __tablename__ = "invoice_items"

    id = Column(Integer, primary_key=True, index=True)
    invoice_id = Column(Integer, ForeignKey("invoices.id"))
    name = Column(String, nullable=False)
    quantity = Column(Float, default=1.0)
    price_per_unit = Column(Float, default=0.0)

    invoice = relationship("Invoice", back_populates="items")


class MonthlySpending(Base):
    """
    Example table for monthly spend tracking. 
    Another 'ALWAYS_DENY' for writes in baby step, so agent
    cannot do INSERT/UPDATE/DELETE on monthly_spendings.
    """
    __tablename__ = "monthly_spendings"

    id = Column(Integer, primary_key=True, index=True)
    year_month = Column(String, nullable=False)  # e.g. "2025-01"
    total_spent = Column(Float, default=0.0)

###############################################################################
# Create all tables once
###############################################################################
Base.metadata.create_all(bind=engine)

###############################################################################
# Table Permissions
###############################################################################
# We define which tables are ALWAYS_ALLOW, REQUIRE_USER, or ALWAYS_DENY for writes.
# This is used by the 'sql_block' to decide if an INSERT/UPDATE/DELETE is permitted.
table_permissions = {
    "chat_exchanges":    "ALWAYS_DENY",   # never allow writes from the LLM
    "documents":         "ALWAYS_DENY",   # same reason
    "fridge_items":      "ALWAYS_ALLOW",  # can always INSERT/UPDATE
    "shopping_items":    "ALWAYS_ALLOW",  # can always INSERT/UPDATE
    "invoices":          "REQUIRE_USER",  # user_permission=True for now
    "invoice_items":     "REQUIRE_USER",  # user_permission=True for now
    "monthly_spendings": "ALWAYS_DENY"    # denies writes
}

--- main.py ---
# main.py

from fastapi import FastAPI, UploadFile, File, Form, Body
import os
import base64
import uuid
import re
from dotenv import load_dotenv
from datetime import datetime

from database import SessionLocal, ChatExchange, Document
from vectorstore import ingest_document, query_docs
from parser_utils import parse_file

# Import the orchestrator "run_agent"
from agent.orchestrator import run_agent

import openai
import logging

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI()

###############################################################################
# LOGGING SETUP
###############################################################################
logging.basicConfig(
    level=logging.INFO,  # or DEBUG if needed
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
)
logger = logging.getLogger("agent")


###############################################################################
# 1) /api/image_recognize
###############################################################################
@app.post("/api/image_recognize")
async def image_recognize_endpoint(
    file: UploadFile = File(...),
    user_prompt: str = Form(""),
    model: str = Form("gpt-4o-mini")
):
    """
    Example route for image recognition. 
    1) Convert image to base64
    2) Possibly pass to an image-based model
    3) Store results
    """
    db = SessionLocal()
    try:
        # (A) Base64-encode the image
        raw_img = await file.read()
        user_image_b64 = base64.b64encode(raw_img).decode("utf-8")

        # (B) Build content parts (prompt + image)
        content_parts = []
        if user_prompt.strip():
            content_parts.append({"type": "text", "text": user_prompt.strip()})
        content_parts.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{user_image_b64}"}
        })

        # (C) The instructions for the image model
        instructions = (
            "You are an expert image recognition AI. The user may provide a prompt + image. "
            "If no additional prompt is provided, put something like 'How can I help you with this image?' "
            "into the <Response> section.\n"
            "Return EXACT:\n<Title>...</Title>\n<Description>...</Description>\n<Response>...</Response>\n"
        )

        # (D) Call the model
        from openai import OpenAI
        client = OpenAI(api_key=openai.api_key)

        try:
            resp = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": instructions},
                    {"role": "user", "content": content_parts},
                ],
                max_tokens=400,
                temperature=0.7
            )
            llm_text = resp.choices[0].message.content or ""
        except Exception as e:
            logger.error("Error calling the image model: %s", e)
            return {"error": f"Model call failed: {str(e)}"}

        # (E) Parse <Title>, <Description>, <Response>
        title_match = re.search(r"<Title>(.*?)</Title>", llm_text, re.DOTALL)
        desc_match = re.search(r"<Description>(.*?)</Description>", llm_text, re.DOTALL)
        resp_match = re.search(r"<Response>(.*?)</Response>", llm_text, re.DOTALL)

        image_title = title_match.group(1).strip() if title_match else ""
        image_desc = desc_match.group(1).strip() if desc_match else ""
        final_response = resp_match.group(1).strip() if resp_match else llm_text

        # (F) Save to DB
        new_ex = ChatExchange(
            user_message=user_prompt,
            llm_response=final_response,
            user_image_b64=user_image_b64,
            image_title=image_title,
            image_description=image_desc
        )
        db.add(new_ex)
        db.commit()
        db.refresh(new_ex)

        # (G) Also store + embed the image_desc in documents
        new_doc = Document(
            filename=f"image_{new_ex.id}.jpg",
            file_content=raw_img,
            text_content=image_desc,
            description=image_title
        )
        db.add(new_doc)
        db.commit()
        db.refresh(new_doc)

        # optional: vector-store indexing
        if image_desc.strip():
            ingest_document(new_doc.id, image_desc)

        return {
            "title": image_title,
            "description": image_desc,
            "response": final_response,
            "exchange_id": new_ex.id
        }
    finally:
        db.close()


###############################################################################
# 2) /api/chat => text-based short-term memory
###############################################################################
@app.post("/api/chat")
async def chat_endpoint(
    message: str = Form(...),
    model: str = Form("gpt-3.5-turbo")
):
    """
    If user only sends text => short-term memory approach.
    We'll fetch last N messages from DB, passing any 'image_description' as context.
    The model can see ~5 prior user/assistant messages.
    """
    ROLLING_WINDOW_SIZE = 5
    db = SessionLocal()
    try:
        old_exs = db.query(ChatExchange) \
                    .order_by(ChatExchange.timestamp.desc()) \
                    .limit(ROLLING_WINDOW_SIZE).all()
        old_exs.reverse()

        system_msg = {
            "role": "system",
            "content": "You are a helpful text-based assistant. You recall the last few messages."
        }
        conversation = [system_msg]

        for exch in old_exs:
            user_txt = exch.user_message.strip() if exch.user_message else ""
            if exch.image_description and exch.image_description.strip():
                user_txt += f"\n[Previous Image Description: {exch.image_description.strip()}]"

            if user_txt.strip():
                conversation.append({"role": "user", "content": user_txt})

            if exch.llm_response and exch.llm_response.strip():
                conversation.append({"role": "assistant", "content": exch.llm_response.strip()})

        # add the new user text
        conversation.append({"role": "user", "content": message.strip()})

        from openai import OpenAI
        client = OpenAI(api_key=openai.api_key)

        try:
            resp = client.chat.completions.create(
                model=model,
                messages=conversation,
                max_tokens=400,
                temperature=0.7
            )
            llm_msg = resp.choices[0].message.content
        except Exception as e:
            logger.error("Error calling text model: %s", e)
            llm_msg = "(Error calling text model.)"

        # store the conversation
        new_ex = ChatExchange(user_message=message, llm_response=llm_msg)
        db.add(new_ex)
        db.commit()
        db.refresh(new_ex)

        return {"response": llm_msg}
    finally:
        db.close()


###############################################################################
# 3) /api/history => returns text + optional image
###############################################################################
@app.get("/api/history")
def get_chat_history():
    """
    Simple route to return all ChatExchange rows in ascending timestamp order.
    """
    db = SessionLocal()
    try:
        rows = db.query(ChatExchange).order_by(ChatExchange.timestamp.asc()).all()
        hist = []
        for r in rows:
            item = {
                "id": r.id,
                "timestamp": r.timestamp.isoformat(),
                "user_message": r.user_message or "",
                "llm_response": r.llm_response or ""
            }
            if r.user_image_b64:
                item["user_image_b64"] = r.user_image_b64
            if r.image_title:
                item["image_title"] = r.image_title
            if r.image_description:
                item["image_description"] = r.image_description
            hist.append(item)
        return {"history": hist}
    finally:
        db.close()


###############################################################################
# 4) /api/ingest => doc ingestion
###############################################################################
@app.post("/api/ingest")
async def ingest_endpoint(
    file: UploadFile = File(...),
    description: str = Form(None)
):
    """
    Example route for ingesting a file, extracting text, storing in DB, then
    indexing into a vector store for semantic search.
    """
    raw_bytes = await file.read()
    filename = file.filename or f"unknown-{uuid.uuid4()}"
    extension = filename.rsplit(".", 1)[-1].lower()
    text_content = parse_file(raw_bytes, extension)

    if not description or not description.strip():
        base_name = filename.rsplit(".", 1)[0]
        description = base_name

    db = SessionLocal()
    try:
        new_doc = Document(
            filename=filename,
            file_content=raw_bytes,
            text_content=text_content,
            description=description
        )
        db.add(new_doc)
        db.commit()
        db.refresh(new_doc)

        doc_id = new_doc.id
        if text_content.strip():
            ingest_document(doc_id, text_content)

        return {
            "status": "ok",
            "doc_id": doc_id,
            "filename": filename,
            "description": description,
            "text_length": len(text_content)
        }
    finally:
        db.close()


###############################################################################
# 5) /api/search_docs => vector search
###############################################################################
@app.post("/api/search_docs")
def search_docs_endpoint(
    query: str = Body(..., embed=True),
    top_k: int = Body(3, embed=True)
):
    """
    Return the top_k similar documents from the vector store.
    """
    results = query_docs(query, top_k=top_k)
    return {"results": results}


###############################################################################
# 6) /api/agent => The new Agent endpoint
###############################################################################
@app.post("/api/agent")
def agent_endpoint(user_input: str = Body(..., embed=True), chosen_model: str = Body("gpt-3.5-turbo", embed=True)):
    logger.info(f"Received user_input for agent: {user_input}")
    # If the frontend sends a model name in the same payload, store it in memory so orchestrator can use it
    task_memory = {}
    if chosen_model and chosen_model.strip():
        task_memory["agent_model"] = chosen_model.strip()

    final_answer, debug_info = run_agent(user_input, task_memory)
    logger.info(f"Final answer from agent: {final_answer}")

    return {
        "final_answer": final_answer,
        "debug_info": debug_info
    }

--- blocks.py ---
# blocks.py

import re
import json
import logging
from typing import Any, Dict

from database import SessionLocal, table_permissions
from sqlalchemy import text

logger = logging.getLogger("agent")

###############################################################################
# Optional synonyms / dictionary
###############################################################################
NAME_SYNONYMS = {
    "tomato": "tomatoes",
    "tomatoe": "tomatoes",
    "tomatoes": "tomatoes",
    # ...
}


def dictionary_normalize_item_name(raw: str) -> str:
    """Example dictionary-based normalization."""
    lowered = raw.strip().lower()
    return NAME_SYNONYMS.get(lowered, lowered)


###############################################################################
# 1) parse_block
###############################################################################
def handle_parse_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    raw_text = args.get("raw_text", "")
    explanation = args.get("explanation", "")
    parsed_item = args.get("parsed_item", {}) or {}

    debug_info.append(f"[parse_block] raw_text={raw_text}, explanation={explanation}")

    # Example: unify name if provided
    if "name" in parsed_item:
        old_name = parsed_item["name"]
        new_name = dictionary_normalize_item_name(old_name)
        parsed_item["name"] = new_name
        debug_info.append(f"[parse_block] Normalized name from '{old_name}' => '{new_name}'")

    task_memory["parsed_item"] = parsed_item
    return {
        "success": True,
        "parsed_item": parsed_item,
        "explanation": explanation
    }


###############################################################################
# 2) build_case_insensitive_where
###############################################################################
def build_case_insensitive_where(where_str: str) -> str:
    """
    Convert "WHERE name='XYZ'" to "WHERE LOWER(name)=LOWER('XYZ')"
    with correct parenthesis. 
    We'll also handle the user possibly using double quotes, e.g. WHERE name="Oranges".
    """

    # Regex approach: look for: WHERE name= 'something' (with optional spaces, single or double quotes)
    # Then rewrite to: WHERE LOWER(name)=LOWER('something')
    pattern = r"(?i)WHERE\s+name\s*=\s*([\"'])(.*?)\1"
    # Explanation:
    #  - (?i) for case-insensitive
    #  - WHERE\s+name\s*=: basic pattern for "WHERE name="
    #  - ([\"']): group 1 is the capturing quote, single or double
    #  - (.*?): group 2 is the actual item name inside the quotes
    #  - \1 is a backreference to the same quote symbol
    replacement = r"WHERE LOWER(name)=LOWER(\1\2\1)"

    # e.g. "WHERE name='tomatoes'" => "WHERE LOWER(name)=LOWER('tomatoes')"
    out = re.sub(pattern, replacement, where_str)
    return out


###############################################################################
# 3) quote_if_needed
###############################################################################
def quote_if_needed(val: str) -> str:
    trimmed = val.strip()
    # if numeric or already single-quoted => return as-is
    if (trimmed.startswith("'") and trimmed.endswith("'")) or trimmed.replace(".", "", 1).isdigit():
        return trimmed
    # else => wrap in single quotes
    return f"'{trimmed}'"


###############################################################################
# 4) handle_sql_block
###############################################################################
def handle_sql_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    table_name = args.get("table_name", "").strip()
    columns = args.get("columns", [])
    values = args.get("values", [])
    action_type = args.get("action_type", "").upper()
    explanation = args.get("explanation", "")
    where_clause = args.get("where_clause", "").strip()

    debug_info.append(
        f"[sql_block] user gave => table={table_name}, cols={columns}, vals={values}, "
        f"action={action_type}, where={where_clause}"
    )

    permission_mode = table_permissions.get(table_name, "ALWAYS_DENY")
    user_permission = True  # For a simple step, assume user is okay with writes

    # SELECT
    if action_type == "SELECT":
        if permission_mode == "ALWAYS_DENY":
            msg = f"[sql_block] SELECT on '{table_name}' => ALWAYS_DENY"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        col_list_str = "*"
        if columns:
            col_list_str = ", ".join(columns)
        sql_query = f"SELECT {col_list_str} FROM {table_name};"
        return run_select_query(sql_query, explanation, debug_info, task_memory)

    # INSERT
    elif action_type == "INSERT":
        if permission_mode == "ALWAYS_DENY":
            msg = f"[sql_block] INSERT => table '{table_name}' => ALWAYS_DENY"
            debug_info.append(msg)
            return {"error": msg}

        if len(columns) != len(values):
            msg = f"[sql_block] Mismatch => columns={columns}, values={values}"
            debug_info.append(msg)
            return {"error": msg}

        col_list_str = ", ".join(columns)
        val_list_str = ", ".join(quote_if_needed(v) for v in values)
        sql_query = f"INSERT INTO {table_name}({col_list_str}) VALUES({val_list_str});"

        debug_info.append(f"[sql_block] final INSERT => {sql_query}")
        return run_write_query(sql_query, explanation, debug_info)

    # UPDATE / DELETE
    elif action_type in ["UPDATE", "DELETE"]:
        if permission_mode == "ALWAYS_DENY":
            msg = f"[sql_block] Writes to '{table_name}' => ALWAYS_DENY"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        if permission_mode == "REQUIRE_USER" and not user_permission:
            msg = f"[sql_block] Write to '{table_name}' => not granted"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        if not where_clause.upper().startswith("WHERE"):
            msg = f"[sql_block] {action_type} requested but no where_clause => not allowed!"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        # Transform => case-insensitive
        ci_where = build_case_insensitive_where(where_clause)
        debug_info.append(f"[sql_block] transformed where => {ci_where}")
        where_clause = ci_where

        if action_type == "UPDATE":
            if len(columns) != len(values):
                msg = f"[sql_block] mismatch col vs val => {columns} vs {values}"
                debug_info.append(msg)
                return {"error": msg}

            set_clauses = []
            for c, v in zip(columns, values):
                set_clauses.append(f"{c}={quote_if_needed(v)}")

            set_stmt = ", ".join(set_clauses)
            sql_query = f"UPDATE {table_name} SET {set_stmt} {where_clause};"
            debug_info.append(f"[sql_block] final UPDATE => {sql_query}")
            return run_write_query(sql_query, explanation, debug_info)

        elif action_type == "DELETE":
            sql_query = f"DELETE FROM {table_name} {where_clause};"
            debug_info.append(f"[sql_block] final DELETE => {sql_query}")
            return run_write_query(sql_query, explanation, debug_info)

    else:
        msg = f"[sql_block] unrecognized action_type={action_type}"
        debug_info.append(msg)
        return {"error": msg}


###############################################################################
# 5) run_select_query
###############################################################################
def run_select_query(sql_query: str, explanation: str, debug_info: list, task_memory: dict) -> dict:
    db = SessionLocal()
    rows_data = []
    error_msg = None
    try:
        debug_info.append(f"[sql_block] Running SELECT => {sql_query}")
        result = db.execute(text(sql_query))
        all_rows = result.fetchall()
        for row in all_rows:
            row_dict = dict(row._mapping)
            rows_data.append(row_dict)

        debug_info.append(f"[sql_block] SELECT => got {len(rows_data)} row(s)")
        logger.info(f"[sql_block] success => SELECT '{sql_query}', rows={len(rows_data)}")

    except Exception as e:
        error_msg = str(e)
        debug_info.append(f"[sql_block] select error => {error_msg}")
        logger.warning(f"[sql_block] SELECT error => {error_msg}")
    finally:
        db.close()

    if error_msg:
        return {"error": error_msg, "sql_query": sql_query}
    task_memory["last_sql_rows"] = rows_data
    return {
        "success": True,
        "rows_data": rows_data,
        "explanation": explanation,
        "rows_count": len(rows_data)
    }


###############################################################################
# 6) run_write_query
###############################################################################
def run_write_query(sql_query: str, explanation: str, debug_info: list) -> dict:
    db = SessionLocal()
    error_msg = None
    rowcount = 0
    try:
        debug_info.append(f"[sql_block] Running WRITE => {sql_query}")
        result = db.execute(text(sql_query))
        rowcount = result.rowcount or 0
        db.commit()

        debug_info.append(f"[sql_block] WRITE => rowcount={rowcount}")
        logger.info(f"[sql_block] success => WRITE '{sql_query}', rowcount={rowcount}")

    except Exception as e:
        error_msg = str(e)
        debug_info.append(f"[sql_block] write error => {error_msg}")
        logger.warning(f"[sql_block] WRITE error => {error_msg}")
        db.rollback()
    finally:
        db.close()

    if error_msg:
        return {"error": error_msg, "sql_query": sql_query}
    return {
        "success": True,
        "rows_affected": rowcount,
        "explanation": explanation
    }


###############################################################################
# 7) handle_output_block
###############################################################################
def handle_output_block(args: Dict[str, Any], task_memory: dict, debug_info: list) -> dict:
    """
    Summarize final result or produce user-facing text.
    If the LLM says "Success" but rowcount=0 or error, we override message.
    """
    llm_message = args.get("final_message", "").strip()
    if not llm_message:
        llm_message = "(No final_message provided by LLM)"

    last_sql_result = task_memory.get("last_sql_block_result", {})
    sql_error = last_sql_result.get("error", "")
    row_affected = last_sql_result.get("rows_affected", None)
    row_count = last_sql_result.get("rows_count", None)

    # 1) error?
    if sql_error:
        # override with actual error message
        final_msg = f"Sorry, an error occurred with your request:\n{sql_error}"
        debug_info.append("[output_block] Overriding LLM message due to SQL error.")
        return {"final_answer": final_msg}

    # 2) If row_affected=0 => override
    if row_affected is not None:
        if row_affected == 0:
            final_msg = (
                "No matching items were found to update/delete. If you expected a change, please check the name."
            )
            debug_info.append("[output_block] Overriding LLM message => no row affected.")
            return {"final_answer": final_msg}
        else:
            debug_info.append("[output_block] Write success => letting LLM message stand.")
            return {"final_answer": llm_message}

    # 3) If row_count for SELECT
    if row_count is not None:
        if row_count == 0:
            final_msg = "No matching items found."
            debug_info.append("[output_block] SELECT => 0 rows => overriding message.")
            return {"final_answer": final_msg}
        else:
            debug_info.append("[output_block] SELECT => letting LLM message stand.")
            return {"final_answer": llm_message}

    # 4) Otherwise let LLM message stand
    debug_info.append("[output_block] letting LLM message stand.")
    return {"final_answer": llm_message}

--- orchestrator.py ---
# agent/orchestrator.py

import json
import os
import logging

from .schemas import ALL_FUNCTION_SCHEMAS, PlanTasksArguments
from .blocks import handle_parse_block, handle_sql_block, handle_output_block

import openai
from openai import OpenAI

logger = logging.getLogger("agent")

def call_openai_plan(user_request: str, debug_info: list, task_memory: dict) -> PlanTasksArguments:
    """
    Asks GPT to produce a short plan of tasks. If GPT returns function_call=plan_tasks, parse it.
    Otherwise fallback parse from content.
    """

    # 1) Load plan instructions from file
    base_dir = os.path.dirname(os.path.abspath(__file__))
    plan_path = os.path.join(base_dir, "prompts", "plan_prompt.md")
    with open(plan_path, "r", encoding="utf-8") as f:
        plan_instructions = f.read()

    # 2) We'll look up the model from task_memory (default gpt-4-0613 if not present)
    model_name = task_memory.get("agent_model", "gpt-4-0613")

    # 3) Build messages
    messages = [
        {"role": "system", "content": plan_instructions},
        {"role": "user", "content": f"USER REQUEST: {user_request}"}
    ]

    # 4) Log
    logger.info(f"[call_openai_plan] user_request='{user_request}'")
    debug_info.append(f"[plan] user_request='{user_request}'")

    # 5) Call GPT with "plan_tasks" schema
    client = OpenAI(api_key=openai.api_key)
    resp = client.chat.completions.create(
        model=model_name,
        messages=messages,
        functions=[fn for fn in ALL_FUNCTION_SCHEMAS if fn["name"] == "plan_tasks"],
        function_call="auto",
        temperature=0.7
    )

    logger.info(f"[call_openai_plan] raw response => {resp}")
    debug_info.append(f"[plan] raw response => {resp}")

    # 6) Parse function_call
    choice = resp.choices[0]
    fn_call = choice.message.function_call

    if fn_call:
        fn_args_str = fn_call.arguments
        debug_info.append(f"[plan] function_call arguments => {fn_args_str}")
        try:
            data = json.loads(fn_args_str)
            plan_args = PlanTasksArguments(**data)

            logger.info(f"[call_openai_plan] Final plan => {plan_args.tasks}")
            debug_info.append(f"[plan] tasks => {plan_args.tasks}")

            return plan_args
        except Exception as e:
            debug_info.append(f"[plan] parse error => {e}")
            logger.warning(f"[call_openai_plan] parse error => {e}")
            return PlanTasksArguments(tasks=[])
    else:
        # fallback parse from .content
        content_str = choice.message.content or ""
        debug_info.append(f"[plan] no function_call, content => {content_str}")
        try:
            candidate = json.loads(content_str)
            if "name" in candidate and "arguments" in candidate:
                plan_args_data = candidate["arguments"]
                plan_args = PlanTasksArguments(**plan_args_data)

                logger.info(f"[call_openai_plan] Final plan => {plan_args.tasks}")
                debug_info.append(f"[plan] tasks => {plan_args.tasks}")
                
                return plan_args
        except:
            pass
        logger.info("[call_openai_plan] no tasks returned")
        return PlanTasksArguments(tasks=[])


def call_block_llm(block_name: str, block_description: str, task_memory: dict, debug_info: list):
    """
    Calls GPT with the appropriate function schema for the block_name.
    If GPT returns no function_call, fallback parse from content. 
    If still no success => error.
    """

    logger.info(f"[call_block_llm] block={block_name}, desc={block_description}")
    debug_info.append(f"[block_llm] block={block_name}, desc={block_description}")

    # 1) Find function schema
    block_schema = None
    for s in ALL_FUNCTION_SCHEMAS:
        if s["name"] == block_name:
            block_schema = s
            break

    if not block_schema:
        msg = f"No schema found for block={block_name}"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}

    # 2) Build system prompt
    system_prompt = build_system_prompt_for_block(block_name, block_description, task_memory)

    # 3) The agent model
    model_name = task_memory.get("agent_model", "gpt-4-0613")

    # 4) Send to GPT
    client = OpenAI(api_key=openai.api_key)
    resp = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": block_description}
        ],
        functions=[block_schema],
        function_call="auto",
        temperature=0.7
    )

    logger.info(f"[call_block_llm] LLM resp => {resp}")
    debug_info.append(f"[block_llm] raw response => {resp}")

    choice = resp.choices[0]
    fn_call = choice.message.function_call
    if not fn_call:
        # fallback parse from .content
        content_str = choice.message.content or ""
        debug_info.append(f"[block_llm] no function_call => fallback parse content = {content_str}")
        try:
            candidate = json.loads(content_str)
            if "name" in candidate and "arguments" in candidate:
                # we can fake a function_call object
                fallback_args = candidate["arguments"]
                logger.info(f"[call_block_llm] fallback parse => block={block_name}, arguments={fallback_args}")
                return dispatch_block(block_name, fallback_args, task_memory, debug_info)
        except Exception as e:
            msg = f"No function_call returned, fallback parse error => {e}"
            debug_info.append(msg)
            logger.warning(msg)
            return {"error": msg}

        # if no parse
        return {"error": "No function_call returned and fallback parse didn't match block=" + block_name}
    else:
        # normal path
        fn_args_str = fn_call.arguments
        debug_info.append(f"[block_llm] function_call args => {fn_args_str}")
        logger.info(f"[call_block_llm] function_call args => {fn_args_str}")

        try:
            args_data = json.loads(fn_args_str)
        except Exception as e:
            debug_info.append(f"[block_llm] JSON parse error => {e}")
            return {"error": f"JSON parse error => {e}"}

        return dispatch_block(block_name, args_data, task_memory, debug_info)


def dispatch_block(block_name: str, args_data: dict, task_memory: dict, debug_info: list):
    logger.info(f"[dispatch_block] block={block_name}, args={args_data}")
    debug_info.append(f"[dispatch_block] block={block_name}, args={args_data}")

    if block_name == "parse_block":
        return handle_parse_block(args_data, task_memory, debug_info)
    elif block_name == "sql_block":
        return handle_sql_block(args_data, task_memory, debug_info)
    elif block_name == "output_block":
        return handle_output_block(args_data, task_memory, debug_info)
    else:
        msg = f"Unrecognized block => {block_name}"
        debug_info.append(msg)
        logger.warning(msg)
        return {"error": msg}


def build_system_prompt_for_block(block_name: str, block_description: str, task_memory: dict) -> str:
    """
    Provide specialized instructions for each block. 
    E.g. show DB schema for sql_block, etc.
    """
    if block_name == "parse_block":
        user_req = task_memory.get("original_user_input", "")
        return (
            "You are the 'parse_block'. You parse raw text into structured data { raw_text, parsed_item }.\n"
            "No disclaimers. Return function_call => { raw_text:'...', explanation:'...', parsed_item:{...}} if needed.\n"
            f"user_input => {user_req}\n"
            f"task_memory => {json.dumps(task_memory, default=str)}"
        )

    elif block_name == "sql_block":           # Here’s a more complete schema block to help the LLM:
        db_schema_str = (
            "Here is your DB schema:\n"
            "- fridge_items:\n"
            "   columns => [id, name, quantity, unit, expiration_date, category]\n"
            "   ALWAYS_ALLOW for writes.\n"
            "- shopping_items:\n"
            "   columns => [id, name, desired_quantity, unit, purchased]\n"
            "   ALWAYS_ALLOW for writes.\n"
            "- invoices:\n"
            "   columns => [id, date, total_amount, store_name]\n"
            "   REQUIRE_USER for writes.\n"
            "- invoice_items:\n"
            "   columns => [id, invoice_id, name, quantity, price_per_unit]\n"
            "   REQUIRE_USER for writes.\n"
            "- monthly_spendings:\n"
            "   columns => [id, year_month, total_spent]\n"
            "   ALWAYS_DENY for writes.\n"
            "\n"
            # If you have more tables or disclaimers, add them here
        )
        return (
            "You are 'sql_block'. You produce { table_name, columns, values, action_type, explanation }.\n"
            "If you do an INSERT, please supply all needed columns. If user didn't specify, use 'misc' or default.\n"
            "For UPDATE or DELETE, you MUST provide where_clause, e.g. \"WHERE name='tomatoes'\".\n\n"
            "If action_type=DELETE, you must provide a where_clause. If the user only says “Delete X,” produce where_clause: \"WHERE name='X'\". No disclaimers.\n"
            "Use EXACT existing table names from the schema below. If you do an INSERT, supply all needed columns.\n"
            + db_schema_str
            + "\n"  # separate line
            + "Example: If user says 'What's on my shopping list?', you select from 'shopping_items'.\n"
            "No disclaimers. You MUST produce a function call object exactly like:\n"
            "{\n"
            '  "name": "sql_block",\n'
            '  "arguments": {\n'
            '     "table_name": "...",\n'
            '     "columns": [...],\n'
            '     "values": [...],\n'
            '     "action_type": "...",\n'
            '     "explanation": "..." \n'
            '     "where_clause": "..." \n'
            '  }\n'
            "}\n\n"
            f"task_memory => {json.dumps(task_memory, default=str)}"
        )

    elif block_name == "output_block":
        last_sql = task_memory.get("last_sql_block_result", {})
        return (
            "You are 'output_block'. Summarize final results. If there's data in last_sql_block_result, show it.\n"
            "Output { 'final_message':'...' } in function_call. No disclaimers.\n"
            f"last_sql_block_result => {json.dumps(last_sql, default=str)}\n"
            f"task_memory => {json.dumps(task_memory, default=str)}"
        )

    else:
        return f"You are block={block_name}, partial memory => {json.dumps(task_memory, default=str)}"


def run_agent(user_input: str, initial_task_memory: dict = None):
    debug_info = []
    if not initial_task_memory:
        initial_task_memory = {}

    task_memory = {"original_user_input": user_input, **initial_task_memory}

    # 1) Plan
    plan_result = call_openai_plan(user_input, debug_info, task_memory)
    if not plan_result.tasks:
        return ("Could not plan tasks. Possibly clarify your request.", debug_info)

    final_answer = "(No final answer produced)"
    output_block_triggered = False

    # 2) Execute steps
    for step in plan_result.tasks:
        block = step.block
        desc = step.description
        res = call_block_llm(block, desc, task_memory, debug_info)

        task_memory[f"last_{block}_result"] = res

        # If it's the output_block, record final_answer
        if block == "output_block":
            output_block_triggered = True
            if "final_answer" in res:
                final_answer = res["final_answer"]
            else:
                # fallback check for "final_message"
                fm = res.get("final_message","")
                if fm:
                    final_answer = fm
            break  # usually we stop after output_block

    # 3) If no output_block was triggered, do a fallback
    if not output_block_triggered:
        # Possibly check last_sql_block_result for success/failure, rowcount, etc.
        # then produce a minimal fallback:
        last_sql_res = task_memory.get("last_sql_block_result", {})
        if "error" in last_sql_res:
            final_answer = (
                "Sorry, an error occurred with your request:\n"
                f"{last_sql_res['error']}"
            )
        else:
            # either row_affected, row_count, or no DB call
            if "rows_affected" in last_sql_res:
                # if row_affected=0 => partial success or no row changed
                ra = last_sql_res["rows_affected"]
                if ra == 0:
                    final_answer = "No rows changed. Possibly the item wasn't found."
                else:
                    final_answer = "Success. The item was changed in the DB."
            elif "rows_count" in last_sql_res:
                # e.g. SELECT
                rc = last_sql_res["rows_count"]
                if rc == 0:
                    final_answer = "No items found."
                else:
                    final_answer = f"Found {rc} item(s)."
            else:
                # no DB call => fallback
                final_answer = "Operation completed, but no final message was produced."

    return (final_answer, debug_info)
--- schemas.py ---
# backend/agent/schemas.py

from typing import List, Optional, Literal, Any
from pydantic import BaseModel


#
# 1) plan_tasks
#
class PlanTaskItem(BaseModel):
    block: str
    description: str
    title: str
    reasoning: str = ""


class PlanTasksArguments(BaseModel):
    tasks: List[PlanTaskItem]


plan_tasks_schema = {
    "name": "plan_tasks",
    "description": (
        "Produce a short plan (a list of tasks) to solve the user request. "
        "Each item has a block name, description, title, and reasoning."
    ),
    "parameters": PlanTasksArguments.schema()
}


#
# 2) sql_block (Method A)
#
class SQLBlockArguments(BaseModel):
    table_name: str
    columns: List[str]    # e.g. ["name","quantity","unit","expiration_date","category"]
    values: List[str]     # e.g. ["'Joghurt'","2","'unit'","'2025-01-25'","'dairy'"]
    action_type: Literal["SELECT", "INSERT", "UPDATE", "DELETE"]
    explanation: str = ""


sql_block_schema = {
    "name": "sql_block",
    "description": (
        "Use this to run a SQL query on the local DB. "
        "No single big sql string—use 'table_name','columns','values','action_type','explanation'. "
        "No disclaimers or code blocks—only valid JSON."
    ),
    "parameters": {
        "type": "object",
        "properties": {
            "table_name": {
                "type": "string",
                "description": "Target DB table, e.g. fridge_items or shopping_items"
            },
            "columns": {
                "type": "array",
                "items": {"type": "string"},
                "description": "Which columns to read/write, e.g. ['name','quantity','unit','expiration_date','category']"
            },
            "values": {
                "type": "array",
                "items": {"type": "string"},
                "description": "Matching values, e.g. ['Joghurt','2','Units','2025-01-25','Dairy']"
            },
            "action_type": {
                "type": "string",
                "enum": ["SELECT","INSERT","UPDATE","DELETE"]
            },
            "explanation": {
                "type": "string",
                "description": "Short explanation or reasoning behind the query"
            },
            "where_clause": {
                "type": "string",
                "description": "Optional WHERE clause if we do an UPDATE or DELETE, e.g. \"WHERE name='tomatoes'\""
            }
        },
        "required": ["table_name","columns","values","action_type"],
        "additionalProperties": False
    }
}


#
# 3) output_block
#
class OutputBlockArguments(BaseModel):
    final_message: str


output_block_schema = {
    "name": "output_block",
    "description": "Produces the final user-facing answer as JSON with 'final_message'.",
    "parameters": {
        "type": "object",
        "properties": {
            "final_message": {
                "type": "string",
                "description": "User-facing text or summary"
            }
        },
        "required": ["final_message"],
        "additionalProperties": False
    }
}


#
# 4) parse_block
#
class ParseBlockArguments(BaseModel):
    raw_text: str
    explanation: Optional[str] = ""
    parsed_item: Optional[Any] = None


parse_block_schema = {
    "name": "parse_block",
    "description": (
        "Parse or unify raw user text into a structured 'parsed_item'. "
        "No disclaimers, just JSON with 'raw_text' and optionally 'parsed_item'."
    ),
    "parameters": {
        "type": "object",
        "properties": {
            "raw_text": {
                "type": "string",
                "description": "The raw text we want to parse"
            },
            "explanation": {
                "type": "string",
                "description": "Short reasoning or explanation"
            },
            "parsed_item": {
                "type": "object",
                "description": "Structured object if needed, e.g. {'name':'Joghurt', 'quantity':2, ...}",
                "additionalProperties": True
            }
        },
        "required": ["raw_text"],
        "additionalProperties": False
    }
}


#
# Gather them all
#
ALL_FUNCTION_SCHEMAS = [
    plan_tasks_schema,
    sql_block_schema,
    output_block_schema,
    parse_block_schema
]

--- App.tsx ---
// frontend/App.tsx
import React from 'react';
import { NavigationContainer } from '@react-navigation/native';
import { createNativeStackNavigator } from '@react-navigation/native-stack';

import { ModelProvider } from './ModelContext';
import HomeScreen from './screens/HomeScreen';
import SettingsScreen from './screens/SettingsScreen';

const Stack = createNativeStackNavigator();

function App() {
  return (
    <ModelProvider>
      <NavigationContainer>
        <Stack.Navigator>
          <Stack.Screen
            name="Home"
            component={HomeScreen}
            options={{headerShown: false}}
          />
          <Stack.Screen name="Settings" component={SettingsScreen} />
        </Stack.Navigator>
      </NavigationContainer>
    </ModelProvider>
  );
}

export default App;
--- HomeScreen.tsx ---
// frontend/screens/HomeScreen.tsx

import React, { useState, useEffect, useContext } from 'react';
import {
  View,
  PermissionsAndroid,
  StyleSheet,
  TouchableOpacity,
  TextInput,
  FlatList,
  Text,
  Image,
  Modal,
} from 'react-native';
import MaterialCommunityIcons from 'react-native-vector-icons/MaterialCommunityIcons';
import Tts from 'react-native-tts';
import AudioRecord from 'react-native-audio-record';
import axios from 'axios';

import {
  launchCamera,
  launchImageLibrary,
  Asset,
} from 'react-native-image-picker';
import DocumentPicker, { types } from 'react-native-document-picker';

import { ModelContext } from '../ModelContext';

// --------------------------------------
// BACKEND ENDPOINTS
// --------------------------------------
const BACKEND_URL = 'http://192.168.0.189:8000';
const BACKEND_TRANSCRIBE_URL = `${BACKEND_URL}/api/transcribe`;
const BACKEND_CHAT_URL = `${BACKEND_URL}/api/chat`;
const BACKEND_INGEST_URL = `${BACKEND_URL}/api/ingest`;
const BACKEND_IMAGE_RECOGNIZE_URL = `${BACKEND_URL}/api/image_recognize`;
const BACKEND_HISTORY_URL = `${BACKEND_URL}/api/history`;

// NEW: Agent endpoint
const BACKEND_AGENT_URL = `${BACKEND_URL}/api/agent`;

// --------------------------------------
// HomeScreen
// --------------------------------------
function HomeScreen({ navigation }: any) {
  const { textModel, imageModel, whisperModel } = useContext(ModelContext);

  // Chat messages
  const [messages, setMessages] = useState<any[]>([]);
  // Recording state
  const [recording, setRecording] = useState(false);

  // If the user picks an image
  const [selectedImageUri, setSelectedImageUri] = useState<string | null>(null);
  // If the user picks a doc
  const [selectedDoc, setSelectedDoc] = useState<{
    uri: string;
    name: string;
    type: string;
  } | null>(null);

  // Typed text input
  const [textMessage, setTextMessage] = useState('');
  // Speaker toggle
  const [speakerOn, setSpeakerOn] = useState(false);

  // Attach menu toggle
  const [showAttachMenu, setShowAttachMenu] = useState(false);

  // Tasks & errors for status popup
  const [tasksInProgress, setTasksInProgress] = useState<string[]>([]);
  const [errors, setErrors] = useState<string[]>([]);
  const [showStatusPopup, setShowStatusPopup] = useState(false);

  // --------------------------------------
  // On mount: fetch chat history
  // --------------------------------------
  useEffect(() => {
    MaterialCommunityIcons.loadFont();
    fetchHistory();
  }, []);

  async function fetchHistory() {
    try {
      console.log('Fetching chat history...');
      const resp = await axios.get(BACKEND_HISTORY_URL);
      const { history } = resp.data;
      const loaded: any[] = [];

      history.forEach((ex: any) => {
        // user text
        if (ex.user_message && ex.user_message.trim()) {
          loaded.push({
            id: ex.id + '-user-text',
            role: 'user',
            type: 'text',
            content: ex.user_message.trim(),
          });
        }
        // user image
        if (ex.user_image_b64) {
          loaded.push({
            id: ex.id + '-user-img',
            role: 'user',
            type: 'image',
            content: `data:image/jpeg;base64,${ex.user_image_b64}`,
          });
        }
        // image title
        if (ex.image_title && ex.image_title.trim()) {
          loaded.push({
            id: ex.id + '-imgtitle',
            role: 'app',
            type: 'text',
            content: `<Title>${ex.image_title.trim()}</Title>`,
          });
        }
        // image description
        if (ex.image_description && ex.image_description.trim()) {
          loaded.push({
            id: ex.id + '-imgdesc',
            role: 'app',
            type: 'text',
            content: `<Description>${ex.image_description.trim()}</Description>`,
          });
        }
        // assistant text
        if (ex.llm_response && ex.llm_response.trim()) {
          loaded.push({
            id: ex.id + '-assistant',
            role: 'app',
            type: 'text',
            content: ex.llm_response.trim(),
          });
        }
      });

      setMessages(loaded);
      console.log('History loaded, total items:', loaded.length);
    } catch (err) {
      console.log('Error fetching history:', err);
      addError(`Fetch history failed: ${err?.message || '(Network error)'}`);
    }
  }

  // --------------------------------------
  // Task & error helpers
  // --------------------------------------
  function addTask(label: string) {
    setTasksInProgress((prev) => [...prev, label]);
    console.log('>>> addTask:', label);
  }
  function removeTask(label: string) {
    setTasksInProgress((prev) => prev.filter((t) => t !== label));
    console.log('>>> removeTask:', label);
  }
  function addError(msg: string) {
    setErrors((prev) => [...prev, msg]);
    console.log('>>> addError:', msg);
  }
  function clearErrors() {
    setErrors([]);
  }
  function toggleStatusPopup() {
    setShowStatusPopup(!showStatusPopup);
  }
  function getStatusButtonStyle() {
    if (errors.length > 0) {
      return { backgroundColor: 'red' };
    } else if (tasksInProgress.length > 0) {
      return { backgroundColor: 'blue' };
    }
    return { backgroundColor: '#555' };
  }
  function getStatusButtonIconName() {
    if (errors.length > 0) {
      return 'alert-circle';
    } else if (tasksInProgress.length > 0) {
      return 'progress-clock';
    }
    return 'information-outline';
  }

  // --------------------------------------
  // AUDIO RECORDING
  // --------------------------------------
  async function requestPermissions() {
    try {
      await PermissionsAndroid.requestMultiple([
        PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
        PermissionsAndroid.PERMISSIONS.WRITE_EXTERNAL_STORAGE,
      ]);
    } catch (err) {
      console.warn(err);
    }
  }
  async function requestCameraPermission() {
    const granted = await PermissionsAndroid.request(
      PermissionsAndroid.PERMISSIONS.CAMERA,
      {
        title: 'Camera Permission',
        message: 'App needs camera access',
        buttonNeutral: 'Ask Me Later',
        buttonNegative: 'Cancel',
        buttonPositive: 'OK',
      }
    );
    return granted === PermissionsAndroid.RESULTS.GRANTED;
  }

  const startRecording = async () => {
    await requestPermissions();
    AudioRecord.init({
      sampleRate: 16000,
      channels: 1,
      bitsPerSample: 16,
    });
    AudioRecord.start();
    setRecording(true);
  };

  const stopRecording = async () => {
    const filePath = await AudioRecord.stop();
    setRecording(false);

    addTask('Transcription');
    try {
      const formData = new FormData();
      formData.append('whisper_model', whisperModel);
      formData.append('file', {
        uri: 'file://' + filePath,
        name: 'audio.wav',
        type: 'audio/wav',
      } as any);

      const resp = await axios.post(BACKEND_TRANSCRIBE_URL, formData, {
        headers: { 'Content-Type': 'multipart/form-data' },
      });
      removeTask('Transcription');

      const transcript = resp.data.transcript || '';
      setTextMessage(transcript);
    } catch (error: any) {
      removeTask('Transcription');
      const msg = error?.message || '(Network error)';
      addError(`Transcription failed: ${msg}`);
      console.log('Error transcribing audio:', error);
    }
  };

  // --------------------------------------
  // ATTACH MENU
  // --------------------------------------
  function toggleAttachMenu() {
    setShowAttachMenu(!showAttachMenu);
  }

  // --------------------------------------
  // CAMERA / GALLERY / DOC
  // --------------------------------------
  const handleTakePhoto = async () => {
    toggleAttachMenu();
    const hasCam = await requestCameraPermission();
    if (!hasCam) {
      console.log('Camera permission denied');
      return;
    }
    const result = await launchCamera({ mediaType: 'photo' });
    if (!result.didCancel && !result.errorCode && result.assets?.length) {
      const asset: Asset = result.assets[0];
      if (asset.uri) {
        setSelectedImageUri(asset.uri);
      }
    }
  };

  const handleChooseFromGallery = async () => {
    toggleAttachMenu();
    const result = await launchImageLibrary({ mediaType: 'photo' });
    if (!result.didCancel && !result.errorCode && result.assets?.length) {
      const asset: Asset = result.assets[0];
      if (asset.uri) {
        setSelectedImageUri(asset.uri);
      }
    }
  };

  const handlePickDoc = async () => {
    toggleAttachMenu();
    try {
      const res = await DocumentPicker.pickSingle({
        presentationStyle: 'fullScreen',
        type: [types.pdf, types.docx, types.plainText],
      });
      console.log('Picked doc:', res);
      if (res.uri) {
        setSelectedDoc({
          uri: res.uri,
          name: res.name ?? 'unnamed',
          type: res.type ?? 'application/octet-stream',
        });
      }
    } catch (err) {
      if (DocumentPicker.isCancel(err)) {
        console.log('User canceled doc picker');
      } else {
        console.log('Document pick error:', err);
      }
    }
  };

  // --------------------------------------
  // Normal Chat / Doc / Image
  // --------------------------------------
  const sendMessage = async () => {
    // 1) If doc
    if (selectedDoc) {
      addTask('Doc Ingestion');
      try {
        const formData = new FormData();
        formData.append('file', {
          uri: selectedDoc.uri,
          type: selectedDoc.type,
          name: selectedDoc.name,
        } as any);
        formData.append('description', textMessage);

        const resp = await axios.post(BACKEND_INGEST_URL, formData, {
          headers: { 'Content-Type': 'multipart/form-data' },
        });
        removeTask('Doc Ingestion');

        console.log('Doc ingestion resp:', resp.data);
        setMessages((prev) => [
          ...prev,
          {
            id: `doc-ingest-${Date.now()}`,
            role: 'app',
            type: 'text',
            content: `Doc Ingested => ID=${resp.data.doc_id}, Desc="${resp.data.description}"`,
          },
        ]);
      } catch (error: any) {
        removeTask('Doc Ingestion');
        const msg = error?.message || '(Network error)';
        addError(`Doc ingestion failed: ${msg}`);
        console.log('Error ingesting doc:', error);
      }
      setSelectedDoc(null);
      setTextMessage('');
      return;
    }

    // 2) If image => /api/image_recognize
    if (selectedImageUri) {
      const trimmed = textMessage.trim();
      if (trimmed) {
        setMessages((prev) => [
          ...prev,
          {
            id: `user-txt-${Date.now()}`,
            role: 'user',
            type: 'text',
            content: trimmed,
          },
          {
            id: `user-img-${Date.now()}`,
            role: 'user',
            type: 'image',
            content: selectedImageUri,
          },
        ]);
      } else {
        setMessages((prev) => [
          ...prev,
          {
            id: `user-img-${Date.now()}`,
            role: 'user',
            type: 'image',
            content: selectedImageUri,
          },
        ]);
      }

      addTask('Image Recognition');
      try {
        const formData = new FormData();
        formData.append('file', {
          uri: selectedImageUri,
          type: 'image/jpeg',
          name: 'photo.jpg',
        } as any);
        formData.append('user_prompt', trimmed);
        formData.append('model', imageModel);

        const resp = await axios.post(BACKEND_IMAGE_RECOGNIZE_URL, formData, {
          headers: { 'Content-Type': 'multipart/form-data' },
        });
        removeTask('Image Recognition');

        const { title, description, response } = resp.data || {};
        console.log('image_recognize resp:', resp.data);

        if (title && title.trim()) {
          setMessages((prev) => [
            ...prev,
            {
              id: `app-imgtitle-${Date.now()}`,
              role: 'app',
              type: 'text',
              content: `<Title>${title}</Title>`,
            },
          ]);
        }
        if (description && description.trim()) {
          setMessages((prev) => [
            ...prev,
            {
              id: `app-imgdesc-${Date.now()}`,
              role: 'app',
              type: 'text',
              content: `<Description>${description}</Description>`,
            },
          ]);
        }
        const finalResp = response || '(No response)';
        setMessages((prev) => [
          ...prev,
          {
            id: `app-imgresp-${Date.now()}`,
            role: 'app',
            type: 'text',
            content: `<Response>${finalResp}</Response>`,
          },
        ]);
        if (speakerOn) {
          Tts.speak(finalResp);
        }
      } catch (error: any) {
        removeTask('Image Recognition');
        const msg = error?.message || '(Network error)';
        addError(`Image recognition failed: ${msg}`);
        console.log('Error sending image:', error);
      }
      setSelectedImageUri(null);
      setTextMessage('');
      return;
    }

    // 3) Else => normal text => /api/chat
    const trimmed = textMessage.trim();
    if (!trimmed) return;

    const userMsgId = `user-msg-${Date.now()}`;
    setMessages((prev) => [
      ...prev,
      { id: userMsgId, role: 'user', type: 'text', content: trimmed },
    ]);

    addTask('Chat Request');
    try {
      const formData = new FormData();
      formData.append('model', textModel);
      formData.append('message', trimmed);

      setTextMessage('');

      const resp = await axios.post(BACKEND_CHAT_URL, formData, {
        headers: { 'Content-Type': 'multipart/form-data' },
      });
      removeTask('Chat Request');

      const reply = resp.data.response || '(No response)';
      if (speakerOn) Tts.speak(reply);
      setMessages((prev) => [
        ...prev,
        { id: `app-msg-${Date.now()}`, role: 'app', type: 'text', content: reply },
      ]);
    } catch (error: any) {
      removeTask('Chat Request');
      const msg = error?.message || '(Network error)';
      addError(`Chat request failed: ${msg}`);
      console.log('Error sending text chat:', error);
    }
  };

  // --------------------------------------
  // Agent call
  // --------------------------------------
  async function callAgentApi(userInput: string) {
    if (!userInput.trim()) return;
    addTask('Agent Request');
    try {
      const resp = await axios.post(`${BACKEND_URL}/api/agent`, {
        user_input: textMessage.trim(),
        chosen_model: textModel,
      });
      removeTask('Agent Request');

      const { final_answer, debug_info } = resp.data;
      console.log("Agent Debug Info:", debug_info);  // log to console
      setMessages((prev) => [
        ...prev,
        {
          id: `agent-user-${Date.now()}`,
          role: 'user',
          type: 'text',
          content: userInput,
        },
        {
          id: `agent-answer-${Date.now()}`,
          role: 'app',
          type: 'text',
          content: final_answer,
        },
      ]);
    } catch (error: any) {
      removeTask('Agent Request');
      const msg = error?.message || '(Network error)';
      addError(`Agent error: ${msg}`);
      console.log('Error calling agent:', error);
    }
  }

  // --------------------------------------
  // SPEAKER TOGGLE
  // --------------------------------------
  function toggleSpeaker() {
    setSpeakerOn((prev) => !prev);
  }

  // --------------------------------------
  // RENDER MESSAGES
  // --------------------------------------
  const renderMessage = ({ item }: { item: any }) => {
    const isUser = item.role === 'user';
    const bubbleStyle = isUser
      ? [styles.bubble, styles.userBubble]
      : [styles.bubble, styles.appBubble];
    const textStyle = isUser ? styles.userText : styles.appText;

    if (item.type === 'image') {
      return (
        <View style={bubbleStyle}>
          <Image source={{ uri: item.content }} style={styles.imageBubble} />
        </View>
      );
    }
    return (
      <View style={bubbleStyle}>
        <Text style={textStyle}>{item.content}</Text>
      </View>
    );
  };

  // --------------------------------------
  // FINAL RENDER
  // --------------------------------------
  return (
    <View style={styles.container}>
      <FlatList
        data={messages}
        renderItem={renderMessage}
        keyExtractor={(item) => item.id}
        contentContainerStyle={{ paddingTop: 10, paddingBottom: 80 }}
        style={styles.chatList}
      />

      {/* Selected doc preview */}
      {selectedDoc && (
        <View style={styles.selectedFilePreview}>
          <Text style={{ color: 'gray' }}>{`Doc attached: ${selectedDoc.name}`}</Text>
        </View>
      )}
      {/* Selected image preview */}
      {selectedImageUri && (
        <View style={styles.selectedFilePreview}>
          <Image
            source={{ uri: selectedImageUri }}
            style={{ width: 60, height: 60, borderRadius: 8 }}
          />
          <Text style={{ marginLeft: 10, color: 'gray' }}>Image attached</Text>
        </View>
      )}

      {/* Bottom buttons row */}
      <View style={styles.buttonsRow}>
        <TouchableOpacity
          style={styles.iconButton}
          onPress={() => navigation.navigate('Settings')}
        >
          <MaterialCommunityIcons name="cog-outline" size={30} color="#fff" />
        </TouchableOpacity>

        <TouchableOpacity style={styles.iconButton} onPress={toggleAttachMenu}>
          <MaterialCommunityIcons name="paperclip" size={25} color="#fff" />
        </TouchableOpacity>
        {showAttachMenu && (
          <View style={styles.attachSubMenu}>
            <TouchableOpacity style={styles.subButton} onPress={handlePickDoc}>
              <MaterialCommunityIcons name="file-document" size={24} color="#fff" />
            </TouchableOpacity>
            <TouchableOpacity style={styles.subButton} onPress={handleTakePhoto}>
              <MaterialCommunityIcons name="camera" size={24} color="#fff" />
            </TouchableOpacity>
            <TouchableOpacity style={styles.subButton} onPress={handleChooseFromGallery}>
              <MaterialCommunityIcons name="folder-image" size={24} color="#fff" />
            </TouchableOpacity>
          </View>
        )}

        {/* Status button */}
        <TouchableOpacity
          style={[styles.iconButton, getStatusButtonStyle()]}
          onPress={toggleStatusPopup}
        >
          <MaterialCommunityIcons
            name={getStatusButtonIconName()}
            size={30}
            color="#fff"
          />
        </TouchableOpacity>

        {/* Speaker toggle */}
        <TouchableOpacity
          style={[
            styles.iconButton,
            speakerOn ? { backgroundColor: 'green' } : { backgroundColor: 'red' },
          ]}
          onPress={toggleSpeaker}
        >
          <MaterialCommunityIcons name="volume-high" size={30} color="#fff" />
        </TouchableOpacity>

        {/* Microphone */}
        <TouchableOpacity
          style={[styles.iconButton, recording && styles.recording]}
          onPress={recording ? stopRecording : startRecording}
        >
          <MaterialCommunityIcons name="microphone" size={30} color="#fff" />
        </TouchableOpacity>

        {/* NEW: Robot (Agent) Button */}
        <TouchableOpacity
          style={styles.iconButton}
          onPress={() => {
            if (textMessage.trim()) {
              callAgentApi(textMessage.trim());
              setTextMessage('');
            }
          }}
        >
          <MaterialCommunityIcons name="robot" size={30} color="#fff" />
        </TouchableOpacity>
      </View>

      {/* Input row */}
      <View style={styles.inputRow}>
        <TextInput
          style={styles.textInput}
          placeholder="Type your message or doc description..."
          value={textMessage}
          onChangeText={setTextMessage}
        />
        <TouchableOpacity style={styles.sendButton} onPress={sendMessage}>
          <MaterialCommunityIcons name="send" size={24} color="#fff" />
        </TouchableOpacity>
      </View>

      {/* Status Popup */}
      <Modal
        visible={showStatusPopup}
        transparent
        animationType="fade"
        onRequestClose={() => setShowStatusPopup(false)}
      >
        <View style={styles.overlay}>
          <View style={styles.popup}>
            <Text style={styles.popupTitle}>Status</Text>

            <Text style={styles.popupSubTitle}>Tasks in progress:</Text>
            {tasksInProgress.length === 0 && (
              <Text style={styles.popupText}>No active tasks.</Text>
            )}
            {tasksInProgress.map((t, idx) => (
              <Text key={idx} style={styles.popupText}>
                - {t}
              </Text>
            ))}

            <Text style={[styles.popupSubTitle, { marginTop: 10 }]}>
              Errors:
            </Text>
            {errors.length === 0 && (
              <Text style={styles.popupText}>No errors.</Text>
            )}
            {errors.map((e, idx) => (
              <Text key={idx} style={[styles.popupText, { color: 'red' }]}>
                - {e}
              </Text>
            ))}

            {/* Close / Clear */}
            <View style={styles.popupButtonsRow}>
              <TouchableOpacity
                style={styles.popupButton}
                onPress={() => setShowStatusPopup(false)}
              >
                <Text style={{ color: '#fff' }}>Close</Text>
              </TouchableOpacity>
              <TouchableOpacity
                style={styles.popupButton}
                onPress={() => clearErrors()}
              >
                <Text style={{ color: '#fff' }}>Clear Errors</Text>
              </TouchableOpacity>
            </View>
          </View>
        </View>
      </Modal>
    </View>
  );
}

export default HomeScreen;

// --------------------------------------
// Styles
// --------------------------------------
const styles = StyleSheet.create({
  container: {
    flex: 1,
    marginTop: 40,
    backgroundColor: '#f0f0f0',
  },
  chatList: {
    flex: 1,
  },
  bubble: {
    marginVertical: 4,
    marginHorizontal: 8,
    maxWidth: '70%',
    borderRadius: 12,
    padding: 8,
  },
  userBubble: {
    alignSelf: 'flex-end',
    backgroundColor: '#007aff',
  },
  appBubble: {
    alignSelf: 'flex-start',
    backgroundColor: '#ddd',
  },
  userText: {
    color: '#fff',
  },
  appText: {
    color: '#333',
  },
  imageBubble: {
    width: 150,
    height: 150,
    borderRadius: 8,
  },
  selectedFilePreview: {
    flexDirection: 'row',
    alignItems: 'center',
    marginLeft: 8,
    marginBottom: 5,
  },
  buttonsRow: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'center',
    paddingVertical: 8,
  },
  iconButton: {
    width: 50,
    height: 50,
    borderRadius: 25,
    backgroundColor: '#555',
    justifyContent: 'center',
    alignItems: 'center',
    marginHorizontal: 5,
  },
  attachSubMenu: {
    flexDirection: 'row',
    marginLeft: 5,
  },
  subButton: {
    width: 40,
    height: 40,
    borderRadius: 20,
    backgroundColor: '#777',
    justifyContent: 'center',
    alignItems: 'center',
    marginHorizontal: 3,
  },
  recording: {
    backgroundColor: 'red',
  },
  inputRow: {
    flexDirection: 'row',
    alignItems: 'center',
    paddingHorizontal: 8,
    paddingBottom: 10,
  },
  textInput: {
    flex: 1,
    height: 45,
    backgroundColor: '#fff',
    borderRadius: 8,
    paddingHorizontal: 10,
  },
  sendButton: {
    width: 45,
    height: 45,
    borderRadius: 8,
    marginLeft: 8,
    backgroundColor: '#007aff',
    justifyContent: 'center',
    alignItems: 'center',
  },
  overlay: {
    flex: 1,
    backgroundColor: 'rgba(0,0,0,0.4)',
    justifyContent: 'center',
    alignItems: 'center',
  },
  popup: {
    width: '80%',
    backgroundColor: '#fff',
    borderRadius: 8,
    padding: 16,
  },
  popupTitle: {
    fontSize: 18,
    fontWeight: 'bold',
    marginBottom: 10,
    color: '#333',
  },
  popupSubTitle: {
    fontWeight: '600',
    marginBottom: 5,
    color: '#333',
  },
  popupText: {
    color: '#333',
    marginBottom: 2,
  },
  popupButtonsRow: {
    flexDirection: 'row',
    justifyContent: 'flex-end',
    marginTop: 15,
  },
  popupButton: {
    backgroundColor: '#007aff',
    borderRadius: 6,
    paddingHorizontal: 10,
    paddingVertical: 6,
    marginLeft: 10,
  },
});

--- SettingsScreen.tsx ---
// SettingsScreen.tsx
import React, {useContext} from 'react';
import {View, Text, StyleSheet} from 'react-native';
import {Picker} from '@react-native-picker/picker';
import {ModelContext} from '../ModelContext';

export default function SettingsScreen() {
  const {
    textModel, setTextModel,
    imageModel, setImageModel,
    whisperModel, setWhisperModel
  } = useContext(ModelContext);

  return (
    <View style={styles.container}>
      <Text style={styles.title}>Settings</Text>

      {/* TEXT MODEL PICKER */}
      <Text style={styles.label}>Select Text Model:</Text>
      <Picker
        selectedValue={textModel}
        onValueChange={setTextModel}
        style={{ color: 'black', backgroundColor: 'white' }}
        itemStyle={{ color: 'black' }}
      >
        {/* Replace or add any text-based models you want */}
        <Picker.Item label="GPT-3.5 Turbo"        value="gpt-3.5-turbo" />
        <Picker.Item label="GPT-3.5 Turbo (16k)"  value="gpt-3.5-turbo-16k" />
        <Picker.Item label="GPT-4"               value="gpt-4" />
        <Picker.Item label="GPT-4 (0613)"        value="gpt-4-0613" />
        {/* or add more if needed */}
      </Picker>

      {/* IMAGE MODEL PICKER */}
      <Text style={styles.label}>Select Image Model:</Text>
      <Picker
        selectedValue={imageModel}
        onValueChange={setImageModel}
        style={{ color: 'black', backgroundColor: 'white' }}
        itemStyle={{ color: 'black' }}
      >
        {/* Replace with whatever 'Vision' models you have */}
        <Picker.Item label="GPT-4o" value="gpt-4o" />
        <Picker.Item label="GPT-4o-mini" value="gpt-4o-mini" />
      </Picker>

      {/* WHISPER MODEL PICKER */}
      <Text style={styles.label}>Select Whisper Model:</Text>
      <Picker
        selectedValue={whisperModel}
        onValueChange={setWhisperModel}
        style={{ color: 'black', backgroundColor: 'white' }}
        itemStyle={{ color: 'black' }}
      >
        <Picker.Item label="tiny" value="tiny" />
        <Picker.Item label="base" value="base" />
        <Picker.Item label="small" value="small" />
        <Picker.Item label="medium" value="medium" />
        <Picker.Item label="large" value="large" />
      </Picker>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, padding: 16, marginTop: 40, backgroundColor: '#fff' },
  title: { fontSize: 20, marginBottom: 20, color: 'black' },
  label: { marginTop: 20, marginBottom: 5, color: 'black' },
  picker: { height: 50, width: 220 },
});
